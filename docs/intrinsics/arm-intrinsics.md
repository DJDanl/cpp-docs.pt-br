---
title: Intr√≠nsecos ARM
ms.date: 09/02/2019
f1_keywords:
- arm_neon/vsetq_lane_p8
- armintr/_arm_uxtb
- arm_neon/vld4_lane_p8
- arm_neon/vrshrn_n_s64
- arm_neon/vsli_n_u32
- arm_neon/vsraq_n_u16
- arm_neon/vcgt_f32
- armintr/__iso_volatile_store32
- arm_neon/vceqq_f32
- armintr/_arm_smlal
- arm_neon/vmull_n_s32
- arm_neon/vmax_s8
- arm_neon/vmvn_u32
- arm_neon/vrshl_u32
- arm_neon/int32x2_t
- arm_neon/vdupq_n_p8
- arm_neon/vpmax_u16
- arm_neon/vtrnq_s32
- arm_neon/vset_lane_f32
- arm_neon/vrev64_s8
- arm_neon/vtrnq_p8
- arm_neon/vqshlq_u64
- arm_neon/vld1q_dup_s64
- arm_neon/vmovq_n_u64
- arm_neon/vqshrn_n_u16
- arm_neon/vhadd_s32
- arm_neon/vrhaddq_u32
- arm_neon/vst1q_p8
- arm_neon/vshrn_n_s16
- arm_neon/vget_high_f32
- arm_neon/vuzpq_s16
- arm_neon/vand_u16
- arm_neon/vmulq_s32
- arm_neon/vrsraq_n_s64
- arm_neon/vceqq_s8
- arm_neon/uint64x1x3_t
- arm_neon/veor_u32
- armintr/_arm_pkhtb
- arm_neon/vorrq_u16
- arm_neon/vpaddl_s8
- arm_neon/vmla_n_s16
- arm_neon/vqdmlal_lane_s32
- arm_neon/vshlq_n_u8
- arm_neon/vst2_lane_p8
- arm_neon/vld3q_u16
- arm_neon/vandq_u8
- arm_neon/vst1_u64
- arm_neon/vaddq_s64
- arm_neon/vuzpq_u32
- arm_neon/vld3_lane_p8
- arm_neon/vminq_s32
- arm_neon/vabd_u16
- arm_neon/vdup_n_u32
- arm_neon/vmul_p8
- arm_neon/vsra_n_u16
- arm_neon/vst3q_u16
- arm_neon/int32x2x3_t
- arm_neon/vld2_dup_u16
- arm_neon/vrhaddq_u8
- arm_neon/vhadd_u8
- arm_neon/vgetq_lane_s32
- arm_neon/vcleq_u16
- arm_neon/vabdq_s8
- arm_neon/vrev16q_u8
- arm_neon/vqshlu_n_s64
- arm_neon/vcvt_n_s32_f32
- arm_neon/vqrshrn_n_s64
- arm_neon/vst1q_p16
- arm_neon/vgetq_lane_s16
- arm_neon/vtstq_u32
- arm_neon/vmlsl_n_s16
- arm_neon/vcge_s8
- arm_neon/vshr_n_s16
- armintr/_arm_rbit
- arm_neon/vmls_u32
- arm_neon/vmls_lane_u32
- arm_neon/vcvtq_n_s32_f32
- arm_neon/vqshl_n_s8
- arm_neon/vst1q_s16
- armintr/__emit
- arm_neon/vshlq_s64
- arm_neon/vuzp_s8
- arm_neon/vld1q_lane_s64
- arm_neon/veorq_s32
- arm_neon/vaddq_u64
- arm_neon/vceq_s32
- arm_neon/vmovn_u16
- arm_neon/vabal_s8
- arm_neon/vabsq_f32
- armintr/_arm_smuad
- arm_neon/veor_u8
- arm_neon/int16x4_t
- arm_neon/vsraq_n_s16
- arm_neon/vshlq_s8
- arm_neon/vcreate_u32
- arm_neon/vzipq_s8
- arm_neon/vst3q_u8
- arm_neon/int64x1x4_t
- armintr/__iso_volatile_store16
- arm_neon/vst4_lane_p16
- arm_neon/vld1_dup_p16
- arm_neon/vhadd_s16
- arm_neon/vtbl2_s8
- arm_neon/veorq_u32
- arm_neon/vqdmlal_lane_s16
- arm_neon/vrsra_n_u8
- arm_neon/vbslq_u16
- arm_neon/vget_low_s64
- arm_neon/vceq_u16
- arm_neon/vdupq_lane_u32
- arm_neon/vabdl_u32
- arm_neon/vmlal_s32
- arm_neon/vst1_lane_u8
- arm_neon/vld4q_f16
- arm_neon/vqdmlsl_s32
- arm_neon/vqrdmulh_s32
- arm_neon/vqrshl_u8
- arm_neon/uint32x4x4_t
- arm_neon/vabaq_u16
- arm_neon/vcnt_p8
- arm_neon/vld3q_s16
- arm_neon/vshl_n_u32
- arm_neon/vrev64q_u16
- arm_neon/vextq_s64
- arm_neon/vhsubq_s8
- arm_neon/vld2_dup_u8
- arm_neon/vst3_s16
- arm_neon/vorn_u16
- arm_neon/vst4_f16
- arm_neon/vpadalq_u8
- armintr/__iso_volatile_load8
- arm_neon/vmovl_u16
- arm_neon/vld4q_u32
- arm_neon/vcgt_u32
- arm_neon/vmlaq_n_u32
- arm_neon/vrsra_n_u64
- arm_neon/vst4_s8
- arm_neon/vcvtq_n_f32_u32
- arm_neon/vst2q_u16
- arm_neon/vqshrn_n_s16
- arm_neon/vld4_s16
- arm_neon/uint16x8x4_t
- arm_neon/vrsqrte_u32
- arm_neon/vcltq_s8
- arm_neon/vst3_u16
- arm_neon/vst2_f32
- arm_neon/vld2_u64
- arm_neon/vst1_u16
- arm_neon/vmls_s16
- arm_neon/vqrshlq_s32
- arm_neon/vqdmull_s16
- arm_neon/vld2_lane_p16
- arm_neon/vpaddlq_u8
- arm_neon/vcvt_n_f32_u32
- arm_neon/vcgtq_u8
- arm_neon/vshl_s32
- arm_neon/vtbx3_p8
- arm_neon/vld3_dup_s32
- arm_neon/int16x4x3_t
- arm_neon/vcale_f32
- arm_neon/vqabsq_s32
- arm_neon/vmulq_u16
- arm_neon/vst1_s8
- arm_neon/vclt_u8
- armintr/_arm_sxtb16
- arm_neon/vshr_n_s8
- arm_neon/vst1_lane_f16
- arm_neon/vorn_s64
- armintr/_arm_usub8
- arm_neon/vst4_lane_f32
- arm_neon/vmls_lane_u16
- arm_neon/vpaddl_u32
- arm_neon/vdup_lane_u64
- arm_neon/vsri_n_p16
- arm_neon/vqrshlq_u64
- arm_neon/vclz_s16
- arm_neon/vsra_n_u32
- arm_neon/vabaq_s8
- arm_neon/vst2_lane_s8
- arm_neon/vcvt_n_u32_f32
- arm_neon/vst3_u32
- arm_neon/vcvtq_f32_u32
- arm_neon/vraddhn_s64
- armintr/_arm_uqsax
- arm_neon/vshl_u8
- armintr/_arm_uqadd16
- arm_neon/vrsra_n_u16
- arm_neon/vrshl_u64
- arm_neon/int32x4x3_t
- arm_neon/vmull_u8
- arm_neon/vcombine_u64
- arm_neon/vmull_u16
- arm_neon/vld1_dup_s8
- armintr/_CountLeadingSigns64
- arm_neon/vqshlq_n_s32
- arm_neon/vrecpe_f32
- arm_neon/vsri_n_u32
- arm_neon/vrsraq_n_s8
- arm_neon/vsetq_lane_s16
- arm_neon/vget_high_u32
- arm_neon/vmlal_u32
- arm_neon/vdupq_lane_s16
- arm_neon/vsubq_u64
- arm_neon/vext_p8
- arm_neon/vshl_u16
- arm_neon/vmls_n_u16
- arm_neon/vmull_s16
- arm_neon/vmovq_n_s64
- arm_neon/vaddq_f32
- arm_neon/vshl_n_s16
- arm_neon/vext_p16
- arm_neon/vextq_u32
- arm_neon/vld1_p8
- arm_neon/veor_s32
- arm_neon/int16x8x4_t
- arm_neon/vst1q_u16
- arm_neon/vzipq_p8
- arm_neon/int32x4x4_t
- arm_neon/vqdmulhq_lane_s32
- arm_neon/vst3_lane_u32
- arm_neon/vhsubq_s32
- armintr/__static_assert
- arm_neon/vst3q_lane_u16
- arm_neon/vpmin_u32
- arm_neon/vrev64q_p16
- arm_neon/vcleq_f32
- arm_neon/vhsub_u16
- arm_neon/vld2_lane_s32
- arm_neon/vmlsl_s32
- armintr/_arm_rev
- arm_neon/vcgeq_s16
- arm_neon/vmulq_s8
- arm_neon/vsri_n_s8
- arm_neon/vpadd_f32
- arm_neon/vld1q_lane_f16
- arm_neon/vmls_u16
- arm_neon/vld1_lane_f32
- arm_neon/vmlaq_lane_s16
- arm_neon/vqadd_u32
- arm_neon/vmul_n_s32
- arm_neon/vld1q_dup_p8
- arm_neon/vtrnq_s8
- arm_neon/vbslq_p8
- arm_neon/vget_lane_s8
- arm_neon/vext_u16
- arm_neon/vsubq_s16
- arm_neon/vld4_lane_s8
- arm_neon/uint32x2x2_t
- arm_neon/vdup_n_s8
- arm_neon/vld4_lane_u16
- arm_neon/vmovq_n_s16
- arm_neon/vst4q_s32
- arm_neon/vst2q_f16
- arm_neon/vbslq_s16
- arm_neon/vand_u64
- arm_neon/poly16_t
- arm_neon/vaba_u16
- arm_neon/vqshlq_s64
- armintr/_arm_uxth
- arm_neon/vst2_lane_s16
- arm_neon/vand_u8
- arm_neon/int8x16x3_t
- arm_neon/vrev64_u16
- arm_neon/vld2_lane_s16
- arm_neon/vabaq_s16
- arm_neon/vsli_n_u8
- arm_neon/vsraq_n_u64
- arm_neon/vmlsl_s16
- arm_neon/vmovn_u64
- arm_neon/vld4_f32
- arm_neon/vst2q_f32
- arm_neon/vtbx3_u8
- arm_neon/vcombine_s8
- arm_neon/vqdmulhq_s32
- arm_neon/vgetq_lane_p8
- armintr/_arm_smusd
- arm_neon/vpmax_u32
- arm_neon/vceq_f32
- arm_neon/vsri_n_p8
- arm_neon/vhsubq_u8
- arm_neon/vuzp_s16
- arm_neon/uint32x2x4_t
- arm_neon/vst4_lane_s32
- arm_neon/vsli_n_p8
- arm_neon/vld3_lane_f16
- arm_neon/vbic_u64
- arm_neon/vmlal_u16
- arm_neon/vmvn_s8
- arm_neon/vtstq_s8
- arm_neon/vmaxq_s32
- arm_neon/vqmovn_u64
- armintr/_arm_ssax
- arm_neon/vext_u32
- arm_neon/vld1_dup_u64
- arm_neon/vmlal_n_s16
- armintr/_arm_smulbb
- arm_neon/vqrdmulhq_lane_s16
- arm_neon/vdup_n_p8
- arm_neon/vaba_s8
- arm_neon/vrshrq_n_s32
- arm_neon/vmvnq_s32
- arm_neon/vpadal_s32
- arm_neon/vqshl_s16
- arm_neon/vtrn_p8
- arm_neon/vzip_s16
- arm_neon/vcge_f32
- armintr/_arm_sxtab16
- arm_neon/vst1q_lane_u64
- arm_neon/vqrshlq_u16
- arm_neon/int8x8_t
- arm_neon/vorr_u8
- arm_neon/vrev64_f32
- arm_neon/vpaddlq_s16
- arm_neon/vdupq_lane_u64
- arm_neon/vcltq_u16
- arm_neon/vst3_lane_f32
- arm_neon/vld2_dup_f32
- armintr/_arm_smmul
- arm_neon/vbsl_s16
- arm_neon/vld1_lane_u8
- arm_neon/vld2q_lane_u16
- arm_neon/vqshlu_n_s32
- armintr/_arm_smlalbt
- arm_neon/vmla_s8
- arm_neon/vsli_n_p16
- arm_neon/vmla_u8
- arm_neon/vqaddq_s16
- arm_neon/vld3_p16
- arm_neon/uint64x2x4_t
- arm_neon/vcnt_u8
- arm_neon/vcltq_u8
- arm_neon/vtbx1_p8
- arm_neon/vrev32q_u16
- arm_neon/vld1_lane_u16
- arm_neon/vqadd_s16
- arm_neon/vcnt_s8
- armintr/_MulUnsignedHigh
- arm_neon/vsliq_n_u8
- arm_neon/vpmin_s16
- armintr/__iso_volatile_load16
- arm_neon/vst2_lane_f32
- arm_neon/vqsubq_s32
- arm_neon/vqshl_s32
- arm_neon/vsraq_n_u32
- arm_neon/vcreate_s32
- arm_neon/vld3q_lane_u32
- arm_neon/vaddq_u16
- arm_neon/vand_s32
- arm_neon/vbicq_s32
- armintr/_arm_smulbt
- arm_neon/vrsra_n_s8
- arm_neon/vshrq_n_u32
- arm_neon/vld4_f16
- arm_neon/vcagtq_f32
- arm_neon/vaddw_u32
- armintr/_arm_uxtah
- arm_neon/vtstq_u8
- arm_neon/vld1_dup_u16
- arm_neon/int16x4x4_t
- arm_neon/vqshluq_n_s8
- arm_neon/vqdmulhq_n_s32
- arm_neon/vst1_s64
- arm_neon/vrsubhn_u16
- arm_neon/vld4_dup_p16
- arm_neon/vmlaq_s32
- arm_neon/vnegq_s32
- arm_neon/vst2q_u8
- arm_neon/vget_low_s32
- arm_neon/vorn_u32
- arm_neon/vld1q_s8
- arm_neon/vandq_s64
- arm_neon/vmvn_p8
- arm_neon/vabdl_s16
- arm_neon/vqshl_u32
- arm_neon/vld3_dup_u16
- arm_neon/vmov_n_f32
- arm_neon/vcvt_f32_u32
- arm_neon/vrhadd_s8
- arm_neon/vpadal_u32
- armintr/_arm_ubfx
- arm_neon/vcgt_s8
- arm_neon/vget_lane_f32
- arm_neon/vcge_s16
- arm_neon/vmov_n_s64
- arm_neon/vmulq_n_f32
- arm_neon/vpadalq_u32
- armintr/_arm_smlaldx
- arm_neon/vtst_u16
- arm_neon/vmls_n_s16
- arm_neon/vcombine_f32
- arm_neon/vld1q_p16
- armintr/_arm_ssat
- arm_neon/vextq_s8
- arm_neon/vmax_u32
- arm_neon/vqsubq_s64
- arm_neon/vcltq_s16
- arm_neon/vst2q_s8
- arm_neon/vpmax_u8
- arm_neon/vld4_dup_p8
- arm_neon/vrshr_n_u64
- arm_neon/vqrshrun_n_s16
- arm_neon/vget_low_u64
- arm_neon/vst2q_s32
- arm_neon/vst4_s32
- arm_neon/vrshrq_n_u8
- arm_neon/vdupq_n_u64
- arm_neon/vsriq_n_u8
- arm_neon/vdupq_lane_u8
- arm_neon/vsriq_n_s64
- arm_neon/vget_low_u8
- arm_neon/vst1_lane_p16
- arm_neon/vld1q_lane_u8
- arm_neon/vcgt_s32
- arm_neon/vst1_lane_u32
- arm_neon/vzipq_p16
- arm_neon/vmvn_u16
- arm_neon/vld1q_lane_u16
- armintr/_MoveToCoprocessor64
- arm_neon/vdup_n_u16
- arm_neon/vzipq_f32
- arm_neon/vshl_s16
- arm_neon/vmlaq_n_s16
- arm_neon/vget_lane_s64
- arm_neon/vld1q_lane_f32
- arm_neon/vnegq_s16
- armintr/_arm_usax
- arm_neon/vabd_s16
- arm_neon/vmovq_n_u32
- arm_neon/vshlq_n_u16
- armintr/_CountLeadingSigns
- arm_neon/vld3q_f16
- arm_neon/vceqq_u32
- arm_neon/int8x8x2_t
- arm_neon/vst2_s64
- arm_neon/vst4q_lane_s16
- arm_neon/vorn_s32
- arm_neon/vcle_f32
- arm_neon/vld1_p16
- arm_neon/vtrn_u32
- arm_neon/vbsl_s32
- arm_neon/float32x2_t
- arm_neon/vmvn_s32
- arm_neon/vqdmlsl_lane_s16
- arm_neon/vtbl3_s8
- arm_neon/vsra_n_u8
- arm_neon/vcvtq_u32_f32
- arm_neon/vst1_p8
- arm_neon/vrev64_p16
- armintr/__ldrexd
- arm_neon/vcgeq_u8
- arm_neon/vmlal_n_s32
- arm_neon/vst1q_lane_p8
- arm_neon/vpadalq_s32
- arm_neon/vtstq_p8
- arm_neon/vld4_lane_u8
- armintr/_arm_ssub16
- arm_neon/vpaddlq_u16
- armintr/_arm_udiv
- arm_neon/vld1_lane_p8
- arm_neon/vst1q_u32
- arm_neon/vld1_f32
- arm_neon/uint64x2x2_t
- arm_neon/vqsubq_u64
- arm_neon/vld4q_s32
- arm_neon/vceq_s16
- arm_neon/vst3_s64
- arm_neon/vext_s8
- armintr/_arm_smlsd
- arm_neon/vpadal_s16
- arm_neon/vbic_s32
- arm_neon/vld1_dup_u8
- arm_neon/vclt_f32
- arm_neon/vrev64_s16
- arm_neon/vrshlq_s64
- arm_neon/vdupq_n_s64
- arm_neon/vuzp_p16
- arm_neon/vld3_dup_p16
- arm_neon/vcreate_s8
- armintr/_arm_smlatt
- arm_neon/vtst_s32
- arm_neon/vshrq_n_s64
- arm_neon/vqshlq_n_s64
- arm_neon/vqshlu_n_s16
- arm_neon/vcleq_s16
- arm_neon/vmull_lane_s16
- arm_neon/int32x4_t
- arm_neon/vqadd_s8
- arm_neon/vld2q_f16
- arm_neon/vld2q_lane_p16
- arm_neon/vadd_u32
- arm_neon/vcntq_u8
- arm_neon/vst1_f32
- arm_neon/vmaxq_u32
- arm_neon/vsub_u64
- arm_neon/vsubl_s32
- arm_neon/poly16x4_t
- arm_neon/vgetq_lane_u16
- arm_neon/vdup_lane_s32
- arm_neon/vrhadd_s32
- arm_neon/veorq_u8
- arm_neon/vclzq_s8
- arm_neon/vsliq_n_s64
- arm_neon/vpadalq_s16
- arm_neon/vmla_n_f32
- arm_neon/vcgt_u16
- armintr/_arm_usada8
- arm_neon/vabd_u32
- arm_neon/vgetq_lane_s8
- arm_neon/vqshlq_n_u64
- arm_neon/vabaq_u32
- armintr/_arm_uhsax
- arm_neon/vmulq_f32
- arm_neon/vld3_dup_s16
- arm_neon/vst3_f16
- arm_neon/vrshrq_n_s64
- armintr/__rdpmccntr64
- arm_neon/vclsq_s32
- arm_neon/vmax_u16
- arm_neon/vmvnq_p8
- arm_neon/veor_u16
- arm_neon/vqshrn_n_u32
- arm_neon/vextq_u64
- arm_neon/vld1q_f32
- arm_neon/vget_low_u32
- arm_neon/vhaddq_s32
- arm_neon/vminq_u16
- arm_neon/vqrdmulhq_lane_s32
- arm_neon/vmla_s16
- arm_neon/vadd_s16
- arm_neon/vbsl_u16
- arm_neon/vhsub_s8
- arm_neon/vld4q_lane_p16
- arm_neon/vld1_s16
- arm_neon/vst2q_lane_p16
- arm_neon/vld2_dup_s8
- arm_neon/vst3q_s16
- arm_neon/vcgeq_u32
- arm_neon/vabdq_s16
- arm_neon/vrhadd_u16
- arm_neon/vqshlq_n_u32
- arm_neon/vst4q_lane_u32
- arm_neon/vrsraq_n_u64
- arm_neon/vmlsq_n_s32
- arm_neon/vld4_u8
- arm_neon/vld2_f16
- arm_neon/vqshlq_u8
- arm_neon/vorrq_u64
- arm_neon/vmin_u16
- arm_neon/vext_u8
- arm_neon/vpaddl_s32
- arm_neon/vshlq_u64
- arm_neon/vst2q_lane_f16
- armintr/_arm_sbfx
- arm_neon/vld3_dup_f16
- armintr/_arm_uhasx
- arm_neon/vst2_lane_u8
- armintr/_arm_smultb
- arm_neon/vdup_n_p16
- arm_neon/vtrnq_u32
- arm_neon/vrshlq_u8
- arm_neon/vld4_lane_p16
- arm_neon/vsraq_n_s32
- arm_neon/vclt_s16
- arm_neon/vzip_u8
- arm_neon/vld3_lane_s16
- arm_neon/vceqq_s32
- arm_neon/vld3_dup_f32
- arm_neon/vld4q_lane_s32
- arm_neon/poly8x16x4_t
- arm_neon/uint64x1x2_t
- arm_neon/vqdmlal_n_s16
- arm_neon/vld2_dup_f16
- arm_neon/vshrq_n_s32
- arm_neon/vcleq_s8
- arm_neon/vld3_s32
- arm_neon/vqrshlq_s64
- arm_neon/vbsl_f32
- arm_neon/vext_s64
- arm_neon/vabaq_s32
- arm_neon/vmulq_s16
- arm_neon/vld3_lane_u16
- arm_neon/vld3q_lane_u16
- armintr/_arm_smlaltt
- arm_neon/poly8x8x2_t
- arm_neon/vst3q_u32
- armintr/_arm_smlsdx
- arm_neon/vqrshl_s64
- arm_neon/vextq_p8
- armintr/_arm_uhsub16
- arm_neon/vld3q_p8
- armintr/_arm_smlawt
- armintr/_arm_smlawb
- arm_neon/vdupq_lane_s8
- arm_neon/vaddl_s16
- arm_neon/vcombine_p16
- arm_neon/vzipq_u32
- arm_neon/poly16x8_t
- arm_neon/vshlq_n_s32
- arm_neon/vrshl_s8
- arm_neon/vst2_u64
- arm_neon/vrev64q_s8
- arm_neon/vst2q_lane_s32
- arm_neon/vld2_dup_s16
- arm_neon/vclt_u16
- arm_neon/vuzp_p8
- arm_neon/vshrq_n_s16
- arm_neon/vst3_u64
- arm_neon/vpmin_u16
- arm_neon/vld3q_lane_s32
- arm_neon/vmlal_s16
- arm_neon/poly16x4x4_t
- arm_neon/vorr_u16
- arm_neon/vsliq_n_s16
- arm_neon/vaddl_u8
- arm_neon/vld4_dup_s32
- arm_neon/vld2_f32
- arm_neon/vclt_u32
- arm_neon/vmull_lane_u16
- arm_neon/vsubw_u32
- arm_neon/vld2_dup_s32
- arm_neon/vuzp_s32
- arm_neon/vcge_s32
- arm_neon/vdup_lane_p16
- arm_neon/vpmin_s8
- arm_neon/vpaddlq_u32
- arm_neon/vmlaq_n_s32
- arm_neon/vshrn_n_u64
- arm_neon/vrshr_n_u16
- arm_neon/vld1_s64
- arm_neon/vbsl_u64
- armintr/_arm_smlad
- arm_neon/vqsub_s16
- arm_neon/vld4_p8
- arm_neon/vqdmulh_lane_s32
- arm_neon/vld3_dup_s64
- arm_neon/vornq_s32
- arm_neon/vpadd_u8
- arm_neon/vld3_lane_p16
- arm_neon/uint64x1x4_t
- arm_neon/vld3_u16
- armintr/_arm_shsax
- arm_neon/vabdq_u16
- arm_neon/vcgtq_f32
- arm_neon/vsubq_s8
- arm_neon/vget_low_f16
- arm_neon/vld4_dup_u64
- arm_neon/vst3_lane_s8
- armintr/_arm_ssat16
- arm_neon/vmlaq_f32
- arm_neon/vsri_n_s32
- arm_neon/vmax_u8
- arm_neon/vqadd_u8
- armintr/_arm_uqsub8
- armintr/_arm_clz
- arm_neon/vcgtq_s32
- arm_neon/vraddhn_s32
- arm_neon/vzip_s8
- arm_neon/veorq_s16
- arm_neon/vsetq_lane_s32
- arm_neon/vmul_n_u16
- armintr/_ReadBankedReg
- arm_neon/vld1q_u8
- arm_neon/vld4_p16
- arm_neon/int64x2x2_t
- arm_neon/vmaxq_s8
- arm_neon/vpmax_s16
- arm_neon/vshlq_u16
- arm_neon/vtrnq_p16
- arm_neon/vabal_u16
- arm_neon/vld2_lane_u16
- arm_neon/vrev32_u8
- arm_neon/vrshl_s32
- arm_neon/vget_low_f32
- arm_neon/vld2_s8
- arm_neon/vclzq_s16
- arm_neon/vqdmulhq_n_s16
- arm_neon/vset_lane_u64
- arm_neon/vld2_dup_p16
- arm_neon/vpaddlq_s32
- arm_neon/vld2q_p8
- arm_neon/vst3_lane_u8
- arm_neon/vld4_dup_f32
- arm_neon/vld2_s64
- arm_neon/vmls_u8
- arm_neon/vtbx4_u8
- arm_neon/vsetq_lane_f32
- arm_neon/vcvt_s32_f32
- arm_neon/vst3q_s32
- arm_neon/vmlsq_s8
- arm_neon/vmlaq_n_u16
- armintr/__iso_volatile_load64
- arm_neon/vcgt_u8
- arm_neon/vld2_dup_p8
- arm_neon/vmov_n_u8
- armintr/_arm_sasx
- arm_neon/vmovq_n_p16
- arm_neon/vmlaq_u32
- arm_neon/vst3_f32
- arm_neon/int32x2x4_t
- arm_neon/vld1q_lane_u64
- arm_neon/vclz_u16
- arm_neon/uint8x8_t
- arm_neon/vsub_u32
- arm_neon/vorn_u8
- armintr/__wfe
- arm_neon/vget_high_s16
- arm_neon/vzip_p8
- arm_neon/vmlal_lane_s16
- arm_neon/vmulq_u8
- armintr/_isunordered
- arm_neon/vld1_dup_f32
- arm_neon/vld4_lane_s16
- arm_neon/vdupq_n_s16
- arm_neon/vst3q_p16
- arm_neon/vst1_lane_f32
- arm_neon/float32x4x3_t
- arm_neon/vand_s8
- arm_neon/float32x2x4_t
- arm_neon/vld3_p8
- arm_neon/vmlaq_lane_u16
- armintr/_arm_uqsub16
- arm_neon/vget_high_s32
- arm_neon/vshl_n_s32
- arm_neon/vornq_s8
- arm_neon/vmlsl_n_u32
- arm_neon/vqshlq_n_s8
- arm_neon/int32x2x2_t
- arm_neon/int16x4x2_t
- arm_neon/vceqq_u8
- arm_neon/vcreate_f16
- arm_neon/vorn_s16
- arm_neon/vqmovn_s32
- arm_neon/vextq_u8
- arm_neon/vld4_s32
- armintr/_WriteStatusReg
- arm_neon/uint8x16_t
- arm_neon/vshrn_n_s64
- arm_neon/vmul_n_u32
- arm_neon/vabdl_u8
- arm_neon/vtbx3_s8
- arm_neon/vaddhn_s16
- arm_neon/vld3q_s8
- arm_neon/vmlsl_n_u16
- arm_neon/vrev64q_s32
- arm_neon/int16x8_t
- arm_neon/vext_s32
- arm_neon/vdupq_n_f32
- arm_neon/vld1q_lane_s32
- arm_neon/vqrshlq_u32
- arm_neon/vtbl2_u8
- arm_neon/vgetq_lane_u8
- arm_neon/veorq_u64
- arm_neon/vcntq_s8
- arm_neon/vbslq_p16
- arm_neon/vqnegq_s32
- arm_neon/vaddw_s32
- arm_neon/vmov_n_p8
- arm_neon/vmull_p8
- arm_neon/vld1_lane_u32
- arm_neon/vcombine_s16
- arm_neon/vqshrn_n_s64
- arm_neon/vceqq_s16
- arm_neon/vld4q_p16
- armintr/_ReadStatusReg
- armintr/_arm_qdadd
- arm_neon/uint32x4x2_t
- arm_neon/vcleq_u8
- armintr/_arm_sxtah
- arm_neon/vrhaddq_s32
- arm_neon/vset_lane_s64
- arm_neon/vld4_s64
- armintr/_DAddSatInt
- arm_neon/vorr_s8
- arm_neon/vst2_u32
- arm_neon/vshll_n_u16
- arm_neon/vld2_dup_u32
- arm_neon/vst3q_lane_s32
- arm_neon/vst3q_p8
- armintr/_MoveFromCoprocessor
- arm_neon/uint32x4_t
- arm_neon/vuzpq_s8
- arm_neon/vrecps_f32
- arm_neon/vst1_lane_s8
- arm_neon/vtbx1_s8
- arm_neon/uint16x8x3_t
- arm_neon/vpaddl_s16
- arm_neon/vsubq_s64
- arm_neon/vrsraq_n_u8
- arm_neon/vqadd_s64
- arm_neon/vst4_lane_s16
- arm_neon/vqadd_u16
- arm_neon/vset_lane_u32
- arm_neon/vand_u32
- arm_neon/vrsqrtsq_f32
- arm_neon/vqaddq_u32
- arm_neon/vsra_n_s64
- armintr/_arm_umlal
- arm_neon/vcvt_f32_f16
- arm_neon/vget_lane_u32
- arm_neon/vbsl_s8
- arm_neon/vrshlq_u32
- arm_neon/vqdmull_lane_s16
- arm_neon/vabsq_s32
- arm_neon/vld3_s8
- arm_neon/vst3q_lane_s16
- arm_neon/vld2q_lane_s16
- arm_neon/vst1_lane_s64
- arm_neon/vmov_n_u16
- arm_neon/vst4_lane_u8
- arm_neon/vshll_n_u32
- arm_neon/vqabs_s8
- arm_neon/vmvnq_u8
- arm_neon/vpadalq_u16
- arm_neon/vbsl_p16
- arm_neon/vqrshrn_n_u16
- arm_neon/vld3q_u32
- arm_neon/vcgeq_f32
- armintr/__iso_volatile_load32
- arm_neon/vrecpe_u32
- arm_neon/vld2_dup_u64
- arm_neon/vld3q_f32
- armintr/_arm_shsub8
- arm_neon/vdup_lane_s64
- arm_neon/vqrshl_s8
- arm_neon/vsliq_n_u16
- arm_neon/vld1q_u16
- arm_neon/vorr_u32
- arm_neon/vqrshl_s32
- armintr/__dmb
- arm_neon/veorq_s8
- arm_neon/vld1_u16
- arm_neon/vmov_n_u32
- arm_neon/vhsub_s16
- arm_neon/vst4q_lane_u16
- arm_neon/vbsl_u8
- armintr/_arm_uxtab
- arm_neon/vld2q_lane_f32
- arm_neon/vst2_p8
- armintr/_arm_smmla
- arm_neon/vaddw_u16
- arm_neon/vmlal_s8
- arm_neon/vtst_u32
- arm_neon/vtbl4_u8
- arm_neon/vcvt_n_f32_s32
- arm_neon/vcageq_f32
- arm_neon/vget_low_s16
- arm_neon/vdupq_n_u8
- arm_neon/vorn_s8
- arm_neon/uint8x16x3_t
- arm_neon/vabdq_u32
- arm_neon/vrev64_p8
- arm_neon/vqsubq_s8
- armintr/_arm_smlabb
- arm_neon/vbicq_s64
- arm_neon/vmaxq_u16
- arm_neon/vdup_n_u8
- arm_neon/veor_s8
- arm_neon/int16x8x2_t
- arm_neon/vcvtq_s32_f32
- arm_neon/vtrn_u16
- arm_neon/vbslq_s32
- arm_neon/vld1q_dup_u32
- arm_neon/vmul_n_f32
- arm_neon/vqrshl_u32
- arm_neon/vqsubq_s16
- arm_neon/vst2_lane_f16
- armintr/_arm_smulwt
- arm_neon/vrshrn_n_u32
- arm_neon/vget_high_p16
- arm_neon/vqadd_u64
- arm_neon/vsli_n_s32
- arm_neon/vhadd_u32
- arm_neon/vmlsl_lane_u16
- arm_neon/vclzq_u32
- arm_neon/vqshrun_n_s64
- arm_neon/vrev64q_u32
- arm_neon/vqshrun_n_s16
- arm_neon/vrev32q_s8
- armintr/_arm_shasx
- arm_neon/vaddl_s8
- armintr/_arm_smull
- arm_neon/vabaq_u8
- armintr/_arm_revsh
- arm_neon/vsubq_f32
- arm_neon/poly16x4x2_t
- arm_neon/poly8x8x3_t
- arm_neon/vsubhn_s64
- arm_neon/vcle_u16
- arm_neon/poly8x16x3_t
- arm_neon/vqdmlsl_n_s16
- arm_neon/vqshl_u64
- arm_neon/vcge_u16
- armintr/_arm_uasx
- arm_neon/vmovl_s32
- arm_neon/vst1q_lane_u16
- arm_neon/vbic_u32
- arm_neon/vld2_s16
- armintr/_arm_qasx
- arm_neon/vorrq_u8
- arm_neon/vst2_s32
- armintr/_WriteBankedReg
- arm_neon/veorq_s64
- arm_neon/vld4_lane_f32
- arm_neon/vcreate_u8
- arm_neon/vset_lane_u8
- arm_neon/vandq_u16
- arm_neon/vrsubhn_s64
- arm_neon/vst1q_lane_p16
- arm_neon/uint8x8x2_t
- arm_neon/vmlsl_s8
- arm_neon/vmax_s32
- arm_neon/uint32x4x3_t
- arm_neon/vld4_dup_u16
- arm_neon/vabs_s32
- arm_neon/vld3_dup_u32
- arm_neon/vrshl_u16
- arm_neon/vcle_u8
- arm_neon/vqshl_n_u16
- arm_neon/vbic_s8
- arm_neon/float32x4x2_t
- arm_neon/vmls_f32
- arm_neon/vshll_n_u8
- arm_neon/vminq_s8
- arm_neon/vmlsq_lane_f32
- arm_neon/vst1q_f16
- arm_neon/vst1_lane_u64
- arm_neon/vrhadd_u8
- arm_neon/vclt_s32
- arm_neon/vst2_p16
- arm_neon/vrshrq_n_u16
- arm_neon/vneg_s32
- arm_neon/vmovl_s16
- arm_neon/vqshlq_s8
- arm_neon/vld1_s8
- arm_neon/vqdmulh_s32
- arm_neon/vcls_s8
- armintr/__trap
- arm_neon/vuzp_u32
- armintr/_CopyInt64FromDouble
- arm_neon/int8x16x2_t
- arm_neon/vmovn_s32
- arm_neon/vget_high_s8
- arm_neon/veor_s64
- armintr/_arm_uadd8
- arm_neon/vrev16_u8
- arm_neon/vbicq_u64
- arm_neon/vst4_lane_f16
- arm_neon/vst3_s32
- arm_neon/poly8x8_t
- arm_neon/vtstq_u16
- arm_neon/vld1_lane_s8
- arm_neon/float32x4x4_t
- arm_neon/vst2_s16
- arm_neon/vqrdmulhq_s32
- arm_neon/vqdmulhq_s16
- arm_neon/vrshrq_n_s8
- arm_neon/vcle_s32
- arm_neon/vtbl3_p8
- arm_neon/vbslq_u8
- arm_neon/vst4_u64
- armintr/_arm_umaal
- arm_neon/vshll_n_s8
- arm_neon/vcvt_u32_f32
- arm_neon/vld4q_p8
- arm_neon/vsetq_lane_u16
- arm_neon/vabd_u8
- arm_neon/vclz_u8
- arm_neon/vsubq_u32
- arm_neon/vld1q_lane_p16
- arm_neon/vcgtq_s16
- arm_neon/vmla_lane_s32
- arm_neon/vshlq_n_s64
- arm_neon/vbsl_u32
- arm_neon/vqshlq_s16
- armintr/_arm_qadd8
- arm_neon/vrshr_n_s32
- armintr/_CountOneBits64
- arm_neon/vceq_u32
- arm_neon/vbsl_p8
- arm_neon/uint16x8x2_t
- arm_neon/vsli_n_s16
- arm_neon/vmla_n_s32
- arm_neon/vld4_dup_u32
- arm_neon/vshrq_n_s8
- arm_neon/vqaddq_s8
- arm_neon/vshl_n_u64
- arm_neon/vtbl2_p8
- arm_neon/vcleq_u32
- arm_neon/vqsub_u32
- arm_neon/vmovl_u8
- arm_neon/vmlal_u8
- arm_neon/vmul_s8
- armintr/_MoveFromCoprocessor64
- arm_neon/vrsraq_n_s16
- arm_neon/vdupq_n_u32
- arm_neon/vmov_n_s16
- arm_neon/vst4_lane_p8
- arm_neon/vld1_s32
- arm_neon/vst4_p8
- arm_neon/vsriq_n_u32
- arm_neon/vqdmull_n_s16
- arm_neon/vshlq_u32
- arm_neon/vld3_u8
- armintr/_arm_usub16
- arm_neon/vmlsq_lane_s16
- arm_neon/vmovq_n_s8
- arm_neon/int32x4x2_t
- arm_neon/vld4q_u8
- arm_neon/poly16x8x2_t
- arm_neon/vld1q_u64
- arm_neon/vld3q_lane_s16
- arm_neon/int64x1x2_t
- arm_neon/vshlq_n_s8
- arm_neon/vrshl_s64
- arm_neon/vqshl_n_u8
- armintr/_arm_qadd
- armintr/_DSubSatInt
- armintr/_arm_usat16
- arm_neon/vmull_s8
- arm_neon/vsub_s8
- arm_neon/vmovq_n_u16
- arm_neon/vst4_u16
- arm_neon/vmlsl_lane_u32
- arm_neon/vsliq_n_p16
- arm_neon/vmovn_u32
- arm_neon/vbic_u16
- arm_neon/vtbx2_p8
- arm_neon/vrsubhn_s32
- armintr/_SubSatInt
- arm_neon/vst3_u8
- arm_neon/vdupq_n_s32
- arm_neon/vcntq_p8
- arm_neon/vst4_f32
- arm_neon/vbic_s64
- arm_neon/vld3_s64
- arm_neon/vrsra_n_s64
- arm_neon/vqabsq_s16
- arm_neon/vsriq_n_p8
- arm_neon/vst2_lane_p16
- arm_neon/vabsq_s16
- arm_neon/vcombine_u8
- arm_neon/vld2q_p16
- armintr/_CountOneBits
- armintr/__prefetch
- arm_neon/vld3_dup_u64
- arm_neon/vld2q_s16
- arm_neon/vget_low_p16
- arm_neon/vuzpq_u8
- arm_neon/vrev32q_s16
- armintr/_AddSatInt
- arm_neon/uint16x4x2_t
- arm_neon/vmov_n_s32
- arm_neon/vaddl_u16
- arm_neon/vqaddq_s64
- arm_neon/vmlaq_u16
- arm_neon/vsli_n_s8
- armintr/_arm_sxth
- arm_neon/vorr_s32
- arm_neon/vsra_n_u64
- arm_neon/vst2_f16
- arm_neon/vcombine_u16
- arm_neon/vabs_s16
- arm_neon/vsubhn_s32
- arm_neon/vst1q_lane_u32
- arm_neon/vst3_p8
- arm_neon/vqshrun_n_s32
- arm_neon/vcreate_s64
- arm_neon/vld4q_lane_s16
- arm_neon/vzipq_u16
- arm_neon/vmin_s32
- armintr/_CopyInt32FromFloat
- arm_neon/vcgtq_u32
- arm_neon/vabdl_s32
- arm_neon/vqshlq_n_u16
- arm_neon/int8x16x4_t
- arm_neon/vqrdmulh_n_s32
- arm_neon/vqaddq_u64
- arm_neon/vhaddq_s8
- arm_neon/vshll_n_s16
- arm_neon/vuzp_u8
- arm_neon/vaddl_u32
- arm_neon/vld4q_s16
- arm_neon/vqmovun_s16
- arm_neon/vld1q_lane_s8
- arm_neon/vld2_lane_u32
- arm_neon/vrshr_n_s8
- arm_neon/vmlaq_s16
- armintr/_CopyFloatFromInt32
- arm_neon/vmul_f32
- arm_neon/vmlaq_n_f32
- arm_neon/vst4_s16
- arm_neon/vld1_dup_s32
- arm_neon/vmul_u16
- arm_neon/vhaddq_s16
- arm_neon/vst1q_lane_f32
- arm_neon/vrhaddq_u16
- arm_neon/vbicq_u32
- arm_neon/vrev32_s8
- arm_neon/vmlaq_s8
- arm_neon/vmin_s16
- arm_neon/vst3_lane_p16
- arm_neon/vst2q_lane_f32
- arm_neon/vld4q_lane_f32
- arm_neon/vget_low_u16
- arm_neon/vqsub_s32
- arm_neon/vtbl1_s8
- arm_neon/vmovn_s64
- arm_neon/vpmax_s8
- arm_neon/int8x16_t
- arm_neon/vpmin_u8
- arm_neon/vdup_lane_p8
- arm_neon/vsetq_lane_u64
- arm_neon/vuzpq_u16
- arm_neon/vcgeq_u16
- arm_neon/uint8x16x2_t
- armintr/_arm_rev16
- armintr/_arm_sxtb
- arm_neon/vsliq_n_u64
- arm_neon/vmovq_n_u8
- arm_neon/vshlq_n_u32
- arm_neon/vcombine_s64
- armintr/_arm_qsax
- arm_neon/vmin_f32
- armintr/_arm_sadd16
- arm_neon/vmlsq_n_s16
- arm_neon/vorr_u64
- arm_neon/vqrshrun_n_s64
- arm_neon/vld2q_lane_s32
- arm_neon/vgetq_lane_p16
- arm_neon/vrev32_s16
- arm_neon/vqshl_u16
- arm_neon/vtrn_s8
- arm_neon/vst1q_lane_s64
- arm_neon/vtbl4_p8
- arm_neon/vst1_p16
- arm_neon/vmvn_u8
- arm_neon/vld2_lane_u8
- arm_neon/vld2q_u16
- arm_neon/vmovl_s8
- arm_neon/vbslq_u64
- arm_neon/vmls_s8
- arm_neon/vld3q_p16
- arm_neon/vtbl3_u8
- arm_neon/vabs_f32
- arm_neon/vsraq_n_s8
- arm_neon/vqadd_s32
- arm_neon/vmulq_n_s16
- arm_neon/vst3q_s8
- arm_neon/vaddhn_s64
- arm_neon/vmul_n_s16
- arm_neon/vtbl1_p8
- arm_neon/uint64x2x3_t
- arm_neon/vmlsq_s32
- arm_neon/vld2q_lane_u32
- arm_neon/vaddq_u8
- arm_neon/vcombine_f16
- arm_neon/vandq_s16
- arm_neon/vst4q_lane_p16
- arm_neon/vsri_n_u8
- arm_neon/vst3_lane_p8
- arm_neon/vst3_lane_s16
- arm_neon/vdup_n_s16
- arm_neon/vbicq_s8
- arm_neon/vdup_lane_u8
- arm_neon/vst4q_lane_s32
- arm_neon/vqrshl_u16
- arm_neon/vrsra_n_u32
- arm_neon/vdupq_lane_p8
- arm_neon/vld3_lane_u8
- arm_neon/vqrdmulh_n_s16
- arm_neon/vpmin_s32
- armintr/__cps
- arm_neon/vshl_u32
- armintr/_arm_uadd16
- arm_neon/vld3_s16
- arm_neon/vcvt_f32_s32
- arm_neon/vshlq_n_u64
- arm_neon/vrev64q_u8
- arm_neon/vextq_u16
- arm_neon/vsubl_s16
- arm_neon/vget_lane_p8
- arm_neon/vabal_s16
- arm_neon/vrecpeq_u32
- arm_neon/vminq_u8
- arm_neon/veor_s16
- arm_neon/vmull_n_u16
- arm_neon/vshl_n_u8
- arm_neon/vrev32q_u8
- arm_neon/vandq_s8
- arm_neon/vrshlq_s16
- arm_neon/vst4q_p16
- arm_neon/vandq_s32
- armintr/_MoveToCoprocessor2
- arm_neon/vqdmlsl_lane_s32
- arm_neon/vld1q_s64
- arm_neon/vmull_n_s16
- arm_neon/vneg_s16
- arm_neon/vqshluq_n_s64
- arm_neon/vst2_lane_s32
- arm_neon/vmvnq_u16
- arm_neon/vshll_n_s32
- arm_neon/vld3_dup_s8
- arm_neon/vtstq_s32
- arm_neon/vmlsl_u32
- arm_neon/vqdmulhq_lane_s16
- arm_neon/vaddl_s32
- armintr/_CountLeadingZeros
- arm_neon/vqrshrn_n_s16
- arm_neon/vmla_lane_u32
- arm_neon/vst1_u8
- arm_neon/vshl_u64
- arm_neon/vshr_n_u8
- arm_neon/vmull_lane_s32
- arm_neon/vmlal_lane_u32
- arm_neon/vsubl_s8
- arm_neon/float32x2x2_t
- armintr/_arm_bfc
- arm_neon/vaddq_s16
- arm_neon/vmlal_lane_s32
- arm_neon/vpadd_u16
- arm_neon/vst2q_lane_u16
- arm_neon/vld4_s8
- arm_neon/vst1q_s8
- arm_neon/vshrq_n_u64
- arm_neon/vsli_n_u16
- arm_neon/vqrdmulh_lane_s32
- arm_neon/vst4_lane_u16
- arm_neon/vabdq_f32
- arm_neon/vld2_lane_f16
- arm_neon/vqsub_u64
- arm_neon/vsub_f32
- arm_neon/vld1q_s16
- arm_neon/vmaxq_s16
- arm_neon/vcombine_u32
- arm_neon/vrsraq_n_u32
- armintr/_arm_smusdx
- arm_neon/vrev16_s8
- arm_neon/vqdmulh_n_s32
- arm_neon/vmul_s32
- arm_neon/vabdq_s32
- arm_neon/veor_u64
- arm_neon/vmlsl_n_s32
- arm_neon/vsub_s16
- arm_neon/vadd_u16
- arm_neon/vsriq_n_u16
- arm_neon/vmla_u32
- arm_neon/vuzpq_s32
- arm_neon/vst4q_s8
- arm_neon/vaddhn_u32
- arm_neon/vmlaq_lane_f32
- arm_neon/vld3_lane_s8
- arm_neon/vsliq_n_u32
- arm_neon/vqrshlq_s8
- arm_neon/vqdmlal_n_s32
- arm_neon/uint8x16x4_t
- arm_neon/vcgtq_u16
- arm_neon/vandq_u32
- arm_neon/vld4q_lane_u32
- arm_neon/vzip_p16
- arm_neon/vget_low_p8
- armintr/_arm_shadd8
- arm_neon/vmovn_s16
- arm_neon/vcge_u8
- arm_neon/vld2q_f32
- arm_neon/vaba_u32
- armintr/__iso_volatile_store8
- arm_neon/vst2q_p16
- arm_neon/vmul_s16
- arm_neon/vand_s16
- arm_neon/vtbx4_p8
- arm_neon/vceq_u8
- arm_neon/vrhaddq_s16
- arm_neon/vgetq_lane_f32
- arm_neon/vqshl_s8
- arm_neon/vbslq_f32
- arm_neon/vrsqrts_f32
- arm_neon/vld2q_s8
- arm_neon/vtbl1_u8
- arm_neon/vtst_u8
- arm_neon/vrev64q_f32
- arm_neon/vcle_s8
- arm_neon/vsetq_lane_p16
- arm_neon/vcreate_p16
- arm_neon/vabal_s32
- armintr/_arm_smlald
- arm_neon/vmla_f32
- arm_neon/vtbx2_s8
- arm_neon/int64x1x3_t
- arm_neon/vclz_s8
- arm_neon/vorr_s16
- arm_neon/vornq_s64
- arm_neon/vst1q_u64
- arm_neon/vdupq_n_s8
- armintr/_arm_sadd8
- arm_neon/vextq_s32
- armintr/_arm_smuadx
- armintr/_arm_qsub
- arm_neon/vadd_f32
- arm_neon/vrshrq_n_s16
- arm_neon/vqsub_s8
- arm_neon/vld3_f32
- arm_neon/vhadd_s8
- arm_neon/vmull_n_u32
- arm_neon/vdup_n_u64
- arm_neon/vsubw_s32
- armintr/_arm_sxtab
- armintr/_arm_uxtb16
- arm_neon/vmvn_s16
- arm_neon/vst1_lane_s16
- arm_neon/vqrdmulhq_n_s32
- arm_neon/vsriq_n_s32
- arm_neon/poly8x16x2_t
- arm_neon/vadd_u8
- arm_neon/vuzpq_p8
- arm_neon/vst2q_p8
- armintr/__wfi
- arm_neon/vget_high_u16
- arm_neon/vqrshl_u64
- arm_neon/vld1_dup_s64
- arm_neon/vqrshrn_n_s32
- arm_neon/vrshr_n_s64
- arm_neon/vst3_s8
- arm_neon/poly16x4x3_t
- arm_neon/vqrdmulh_lane_s16
- arm_neon/vmvnq_u32
- arm_neon/vqsubq_u32
- arm_neon/vmovq_n_p8
- arm_neon/vtrn_s16
- arm_neon/vld2q_u32
- arm_neon/vqsubq_u16
- arm_neon/vrsqrteq_u32
- arm_neon/vadd_u64
- armintr/_arm_usat
- arm_neon/vcvtq_n_u32_f32
- arm_neon/vaddq_s8
- arm_neon/vrsraq_n_u16
- arm_neon/vqabs_s16
- arm_neon/vsra_n_s8
- arm_neon/vsra_n_s16
- arm_neon/vqshlq_n_u8
- arm_neon/vpadal_s8
- arm_neon/vmlal_n_u16
- armintr/_CopyDoubleFromInt64
- arm_neon/vaddw_u8
- arm_neon/vmulq_n_s32
- arm_neon/vqaddq_s32
- arm_neon/vmla_lane_f32
- arm_neon/vmlaq_lane_s32
- arm_neon/vld1q_dup_u64
- arm_neon/uint16x8_t
- arm_neon/vld2_s32
- arm_neon/vcltq_f32
- arm_neon/vst4q_f32
- arm_neon/vsri_n_u16
- arm_neon/vshlq_s32
- arm_neon/vgetq_lane_u32
- arm_neon/vld1q_dup_f16
- arm_neon/vrev64q_s16
- arm_neon/vrshrq_n_u32
- arm_neon/vld2q_s32
- arm_neon/vcgtq_s8
- arm_neon/vsubhn_u64
- arm_neon/vmls_n_s32
- armintr/_arm_smmlar
- arm_neon/vld3_dup_u8
- arm_neon/vld3q_lane_p16
- arm_neon/vld2_dup_s64
- arm_neon/vqabs_s32
- arm_neon/vqaddq_u8
- arm_neon/vminq_u32
- arm_neon/vpaddl_u16
- arm_neon/vaba_s16
- arm_neon/vmul_u32
- arm_neon/vst1_lane_u16
- arm_neon/vcreate_f32
- arm_neon/vcvt_f16_f32
- arm_neon/vset_lane_s32
- arm_neon/vshl_s8
- arm_neon/vcgt_s16
- arm_neon/vtrn_f32
- arm_neon/vget_high_s64
- arm_neon/vld3_dup_p8
- arm_neon/vcreate_u64
- arm_neon/vext_u64
- arm_neon/vld1q_dup_s16
- arm_neon/vget_lane_s16
- arm_neon/vqdmlal_s16
- arm_neon/vld2_p16
- arm_neon/vld4_u16
- armintr/_arm_smlalbb
- arm_neon/vrev64_u8
- arm_neon/vbslq_s64
- arm_neon/vsubw_u16
- arm_neon/vrsubhn_u32
- arm_neon/vabdq_u8
- arm_neon/vmls_n_u32
- arm_neon/vshr_n_s32
- arm_neon/vmulq_n_u32
- arm_neon/vst3_p16
- arm_neon/vrev32_u16
- arm_neon/int8x8x3_t
- arm_neon/vst2q_lane_u32
- arm_neon/vextq_p16
- arm_neon/vtrnq_f32
- armintr/_arm_smultt
- arm_neon/vqneg_s8
- arm_neon/vmlsq_lane_s32
- arm_neon/vmov_n_p16
- arm_neon/vraddhn_u64
- arm_neon/vrhadd_u32
- arm_neon/vrev64_u32
- arm_neon/vrshrn_n_s32
- arm_neon/vld4q_f32
- arm_neon/vst2_s8
- arm_neon/vrsqrteq_f32
- arm_neon/uint16x4_t
- arm_neon/vget_low_s8
- arm_neon/vst2_lane_u32
- arm_neon/vhsub_s32
- arm_neon/vqdmull_lane_s32
- armintr/_arm_smulwb
- arm_neon/vmlsl_u8
- arm_neon/vdup_lane_s16
- arm_neon/vtbx4_s8
- arm_neon/vld4q_lane_u16
- arm_neon/vget_high_u8
- arm_neon/vclzq_s32
- arm_neon/vld1q_dup_f32
- arm_neon/vtrn_u8
- arm_neon/vqabsq_s8
- arm_neon/vdup_lane_f32
- arm_neon/vqrdmulh_s16
- arm_neon/vst4_u32
- arm_neon/vdup_lane_u32
- arm_neon/vst4_u8
- arm_neon/vmovq_n_s32
- arm_neon/vld2_lane_s8
- arm_neon/vld3_u32
- arm_neon/vsubl_u16
- arm_neon/vqshlu_n_s8
- arm_neon/float32x4_t
- arm_neon/vqshl_n_s32
- arm_neon/float32x2x3_t
- armintr/__hvc
- arm_neon/vst1q_lane_f16
- arm_neon/vmvnq_s16
- arm_neon/vst3q_lane_f32
- arm_neon/vld1q_dup_u8
- arm_neon/vmlsq_s16
- arm_neon/vget_lane_u8
- arm_neon/vld1_lane_s32
- arm_neon/vst4q_s16
- armintr/_arm_qsub8
- arm_neon/vorrq_s32
- arm_neon/vsriq_n_s8
- arm_neon/vqshrn_n_u64
- arm_neon/vdup_n_s32
- armintr/_arm_uhsub8
- arm_neon/vld3_lane_s32
- arm_neon/vbsl_s64
- arm_neon/vld1_dup_f16
- arm_neon/vsli_n_u64
- arm_neon/vraddhn_u32
- arm_neon/vsub_u16
- arm_neon/vcltq_u32
- arm_neon/vminq_f32
- arm_neon/vshl_n_s64
- arm_neon/vld4_u32
- arm_neon/vld1_u32
- arm_neon/vaddhn_u16
- arm_neon/vcvtq_n_f32_s32
- arm_neon/vorn_u64
- arm_neon/vsubhn_u16
- arm_neon/int64x1_t
- arm_neon/vst1q_lane_s8
- arm_neon/vld1q_dup_s32
- arm_neon/vrev32_p8
- arm_neon/vst3q_lane_p16
- arm_neon/vrecpeq_f32
- arm_neon/int8x8x4_t
- arm_neon/vshr_n_u32
- arm_neon/vdupq_lane_s64
- arm_neon/vpaddlq_s8
- arm_neon/vqshl_n_u32
- arm_neon/vmul_u8
- arm_neon/vtbx2_u8
- arm_neon/vshr_n_u64
- arm_neon/vqrshlq_s16
- arm_neon/vst3_lane_u16
- arm_neon/vqsub_u8
- arm_neon/vrsra_n_s16
- arm_neon/vaba_s32
- arm_neon/vsri_n_u64
- arm_neon/vst3q_lane_u32
- arm_neon/vmlsq_n_u32
- arm_neon/poly8x16_t
- arm_neon/vld2_u8
- armintr/_arm_smmulr
- arm_neon/vtst_s16
- armintr/_arm_smmls
- arm_neon/vqdmulh_s16
- arm_neon/vtrnq_u8
- arm_neon/vset_lane_p8
- arm_neon/vmlsl_u16
- arm_neon/vshrn_n_u16
- arm_neon/vld1_dup_p8
- arm_neon/vrev16q_s8
- arm_neon/vmov_n_s8
- arm_neon/vld1_u64
- arm_neon/vpmin_f32
- arm_neon/vmla_n_u16
- arm_neon/vst1_f16
- arm_neon/vqdmlsl_s16
- arm_neon/vmin_u32
- armintr/_arm_qsub16
- arm_neon/vcage_f32
- arm_neon/vornq_u32
- arm_neon/vpadd_s16
- arm_neon/vld1_u8
- arm_neon/vhsubq_s16
- arm_neon/vld1_dup_u32
- arm_neon/vld4_u64
- armintr/_MulHigh
- arm_neon/vmaxq_u8
- arm_neon/vget_lane_u16
- arm_neon/vld2q_u8
- arm_neon/vld1q_dup_p16
- arm_neon/vsraq_n_u8
- arm_neon/vqdmlsl_n_s32
- arm_neon/vst1_s16
- arm_neon/vst1q_s32
- arm_neon/vmaxq_f32
- arm_neon/vqdmulh_lane_s16
- armintr/__isb
- arm_neon/vuzpq_p16
- arm_neon/vmls_lane_s16
- arm_neon/vtbl4_s8
- arm_neon/vst1_lane_p8
- arm_neon/vsubw_s8
- arm_neon/vmin_u8
- arm_neon/vzip_u16
- arm_neon/vld4q_u16
- arm_neon/vshrn_n_s32
- arm_neon/vpadal_u16
- arm_neon/vorrq_s8
- arm_neon/vrshlq_u64
- arm_neon/vst3_lane_s32
- arm_neon/vqshluq_n_s32
- armintr/_arm_shsub16
- arm_neon/vst1_u32
- arm_neon/vrhadd_s16
- arm_neon/vzipq_s32
- arm_neon/vshrq_n_u16
- arm_neon/vcls_s32
- arm_neon/vceq_s8
- arm_neon/vld2q_lane_f16
- arm_neon/vst4q_u8
- arm_neon/vraddhn_u16
- arm_neon/vget_lane_u64
- armintr/_arm_smlsld
- arm_neon/vld3_u64
- arm_neon/vld1_lane_s16
- arm_neon/vabd_f32
- arm_neon/vdupq_n_u16
- armintr/__iso_volatile_store64
- arm_neon/vqsubq_u8
- arm_neon/poly16x8x3_t
- arm_neon/vcltq_s32
- arm_neon/vqnegq_s16
- arm_neon/vqsub_u16
- arm_neon/vaddq_s32
- arm_neon/vqshl_n_s64
- arm_neon/vabdl_s8
- arm_neon/vclsq_s16
- arm_neon/vpaddl_u8
- arm_neon/vmlsq_n_u16
- armintr/_arm_uqadd8
- arm_neon/vhsub_u32
- arm_neon/vset_lane_s16
- arm_neon/vsubl_u32
- arm_neon/vld3_lane_f32
- arm_neon/vcle_s16
- arm_neon/vmovl_u32
- arm_neon/vst3_lane_f16
- arm_neon/vcaltq_f32
- arm_neon/vsubq_s32
- arm_neon/vand_s64
- arm_neon/vst2_u8
- arm_neon/vcombine_p8
- arm_neon/vqdmlal_s32
- arm_neon/vsub_s32
- armintr/_arm_uxtab16
- arm_neon/vmlsq_n_f32
- armintr/_arm_qdsub
- arm_neon/vhaddq_u32
- arm_neon/vhsubq_u16
- arm_neon/vmlsq_lane_u16
- arm_neon/vst4_s64
- armintr/_CountLeadingOnes
- armintr/_arm_smlabt
- arm_neon/vcombine_s32
- arm_neon/vld4_lane_f16
- arm_neon/vadd_s64
- arm_neon/vorrq_u32
- armintr/__sev
- arm_neon/vdupq_lane_s32
- arm_neon/vrecpsq_f32
- arm_neon/vbicq_u16
- arm_neon/vld1_lane_p16
- arm_neon/vrshr_n_u32
- arm_neon/vcgeq_s32
- arm_neon/vld4_dup_s16
- arm_neon/vld1q_p8
- arm_neon/vrshlq_u16
- arm_neon/vmlaq_lane_u32
- arm_neon/vsub_s64
- arm_neon/vcreate_u16
- arm_neon/vget_lane_s32
- arm_neon/vuzp_f32
- arm_neon/vld2_lane_p8
- arm_neon/vuzp_u16
- arm_neon/vorrq_s16
- armintr/_arm_smlaltb
- arm_neon/vrshrn_n_s16
- arm_neon/vabd_s8
- arm_neon/vnegq_s8
- arm_neon/vst4q_u16
- arm_neon/vst1q_lane_s32
- arm_neon/vst1_lane_s32
- arm_neon/vmla_u16
- arm_neon/vmls_lane_s32
- arm_neon/vtst_s8
- arm_neon/vcgeq_s8
- arm_neon/poly8x8x4_t
- arm_neon/vqsub_s64
- armintr/_arm_uqasx
- arm_neon/vld1_lane_u64
- arm_neon/vminq_s16
- arm_neon/vmulq_u32
- arm_neon/vqrshlq_u8
- arm_neon/vdupq_n_p16
- arm_neon/vld4_dup_f16
- arm_neon/vcls_s16
- arm_neon/vmov_n_u64
- arm_neon/vmla_s32
- arm_neon/vrshl_s16
- arm_neon/vcalt_f32
- arm_neon/int64x2x3_t
- arm_neon/vsub_u8
- arm_neon/vzipq_u8
- arm_neon/vrshrn_n_u64
- arm_neon/vrshlq_s32
- arm_neon/vorr_s64
- arm_neon/vqrshl_s16
- arm_neon/vceqq_u16
- arm_neon/vmulq_n_u16
- arm_neon/vmlaq_u8
- arm_neon/vsri_n_s64
- arm_neon/vld3q_u8
- arm_neon/vld1_dup_s16
- arm_neon/vld1q_s32
- arm_neon/vsri_n_s16
- arm_neon/vshlq_u8
- arm_neon/vsli_n_s64
- arm_neon/vmull_lane_u32
- arm_neon/vshl_s64
- arm_neon/vcreate_s16
- arm_neon/uint8x8x4_t
- arm_neon/vqshrn_n_s32
- arm_neon/vqshlq_u32
- arm_neon/vmlal_n_u32
- arm_neon/vtrnq_s16
- arm_neon/vshr_n_s64
- arm_neon/vst2_u16
- arm_neon/vtrn_s32
- arm_neon/vsubhn_u32
- arm_neon/vbicq_s16
- arm_neon/vsetq_lane_s8
- arm_neon/vrsubhn_s16
- arm_neon/vhsub_u8
- arm_neon/vcleq_s32
- arm_neon/vld4_dup_s8
- arm_neon/vmull_u32
- arm_neon/vrshr_n_s16
- arm_neon/vst1q_lane_s16
- arm_neon/vmlsq_lane_u32
- arm_neon/vnegq_f32
- arm_neon/vmin_s8
- arm_neon/vrev16_p8
- arm_neon/vbic_u8
- arm_neon/vclzq_u16
- arm_neon/vcge_u32
- arm_neon/vget_high_u64
- arm_neon/vabsq_s8
- arm_neon/vhaddq_u16
- arm_neon/vsraq_n_s64
- arm_neon/vld2_u32
- arm_neon/vld2_lane_f32
- arm_neon/vqrshrn_n_u32
- arm_neon/vbslq_s8
- armintr/_CountLeadingZeros64
- arm_neon/vbicq_u8
- arm_neon/vdup_lane_s8
- arm_neon/vpadd_s32
- arm_neon/vld3q_lane_f16
- arm_neon/vaba_u8
- arm_neon/vqshlq_u16
- arm_neon/vst1q_u8
- arm_neon/vst4q_lane_f16
- arm_neon/vshl_n_u16
- armintr/_arm_smladx
- arm_neon/vmla_lane_s16
- arm_neon/vornq_u8
- arm_neon/vqneg_s32
- arm_neon/vadd_s8
- arm_neon/vcle_u32
- arm_neon/vclzq_u8
- arm_neon/vtbx1_u8
- armintr/_CountLeadingOnes64
- armintr/__dsb
- arm_neon/vaddq_u32
- arm_neon/vclsq_s8
- arm_neon/vdup_n_s64
- arm_neon/vmax_s16
- arm_neon/vst2q_u32
- arm_neon/vsetq_lane_s64
- arm_neon/vtst_p8
- arm_neon/vabs_s8
- arm_neon/vqshl_n_s16
- arm_neon/vqrshrn_n_u64
- arm_neon/vaddw_s8
- armintr/_arm_uhadd16
- arm_neon/vsriq_n_p16
- arm_neon/vld4_lane_u32
- arm_neon/vneg_f32
- armintr/_MoveToCoprocessor
- arm_neon/vmvnq_s8
- arm_neon/vld1q_lane_p8
- arm_neon/uint32x2x3_t
- arm_neon/vrshrn_n_u16
- arm_neon/vld3_f16
- arm_neon/vsriq_n_s16
- arm_neon/vshlq_n_s16
- arm_neon/vabal_u8
- arm_neon/vqshluq_n_s16
- arm_neon/vst2_lane_u16
- arm_neon/vbic_s16
- arm_neon/vqshl_n_u64
- arm_neon/vcagt_f32
- arm_neon/vpadalq_s8
- arm_neon/vclz_s32
- arm_neon/vld1_lane_s64
- arm_neon/vget_high_p8
- arm_neon/uint64x1_t
- arm_neon/vextq_s16
- arm_neon/vpadd_s8
- arm_neon/vrsubhn_u64
- arm_neon/vst3q_f16
- arm_neon/vdupq_lane_u16
- arm_neon/vrshrq_n_u64
- arm_neon/vmovq_n_f32
- arm_neon/vld1q_dup_u16
- arm_neon/vshr_n_u16
- arm_neon/uint32x2_t
- armintr/_arm_umull
- arm_neon/vtrnq_u16
- arm_neon/vsetq_lane_u32
- arm_neon/vneg_s8
- arm_neon/vsetq_lane_u8
- arm_neon/vst2q_lane_s16
- arm_neon/vqmovun_s32
- armintr/_arm_usad8
- armintr/_arm_pkhbt
- arm_neon/uint16x4x3_t
- arm_neon/vsra_n_s32
- arm_neon/vqmovun_s64
- arm_neon/vld1q_dup_s8
- arm_neon/vaddhn_s32
- arm_neon/vpmax_f32
- arm_neon/vpadd_u32
- arm_neon/vhsubq_u32
- arm_neon/vqrshrun_n_s32
- arm_neon/vadd_s32
- arm_neon/vclt_s8
- arm_neon/vorrq_s64
- arm_neon/vst4q_f16
- arm_neon/vst1_s32
- arm_neon/vceq_p8
- arm_neon/vsubw_s16
- arm_neon/vgetq_lane_u64
- arm_neon/vmla_n_u32
- arm_neon/vcvtq_f32_s32
- arm_neon/vld1q_u32
- arm_neon/vmax_f32
- armintr/_isunorderedf
- arm_neon/vrshl_u8
- arm_neon/vld4_dup_s64
- arm_neon/vqaddq_u16
- arm_neon/vld4q_lane_f16
- arm_neon/vceqq_p8
- arm_neon/vsubw_u8
- arm_neon/vqmovn_u16
- armintr/_arm_smlsldx
- arm_neon/vcreate_p8
- arm_neon/vqdmull_n_s32
- arm_neon/uint64x2_t
- arm_neon/vmls_s32
- arm_neon/vst3q_f32
- armintr/_arm_bfi
- armintr/_arm_qadd16
- arm_neon/vrshlq_s8
- arm_neon/vget_lane_p16
- arm_neon/vld2_p8
- arm_neon/vld3_lane_u32
- armintr/_MoveFromCoprocessor2
- arm_neon/vqshl_u8
- arm_neon/poly8_t
- arm_neon/vhadd_u16
- arm_neon/vmla_lane_u16
- arm_neon/vshrq_n_u8
- arm_neon/vuzpq_f32
- arm_neon/vmls_lane_f32
- arm_neon/vqneg_s16
- arm_neon/vtrn_p16
- arm_neon/vshrn_n_u32
- arm_neon/vaddhn_u64
- arm_neon/vabal_u32
- arm_neon/vld1q_lane_u32
- arm_neon/vrsraq_n_s32
- arm_neon/vandq_u64
- arm_neon/vqdmull_s32
- arm_neon/vext_s16
- arm_neon/vaddw_s16
- arm_neon/vrev64q_p8
- arm_neon/uint8x8x3_t
- arm_neon/vzip_f32
- armintr/_arm_ssub8
- arm_neon/uint16x4x4_t
- armintr/__swi
- armintr/_arm_smlatb
- arm_neon/vrhaddq_s8
- arm_neon/vpmax_s32
- arm_neon/vqshl_s64
- arm_neon/vrev16q_p8
- arm_neon/vqmovn_u32
- arm_neon/vld1q_f16
- arm_neon/vornq_u64
- arm_neon/vqshlq_n_s16
- arm_neon/vld1_f16
- armintr/_arm_smmlsr
- arm_neon/vshlq_s16
- arm_neon/vsubhn_s16
- arm_neon/vmulq_p8
- arm_neon/vdupq_lane_f32
- armintr/_arm_shadd16
- arm_neon/vornq_s16
- arm_neon/vst1q_lane_u8
- arm_neon/vcaleq_f32
- arm_neon/vst3q_lane_f16
- armintr/_arm_sdiv
- arm_neon/vld2_u16
- arm_neon/vdup_lane_u16
- arm_neon/vst4q_lane_f32
- arm_neon/vdup_n_f32
- arm_neon/vsubq_u8
- arm_neon/vset_lane_p16
- arm_neon/vrsqrte_f32
- arm_neon/vsubl_u8
- arm_neon/vld3q_lane_f32
- arm_neon/vqnegq_s8
- arm_neon/vqmovn_s16
- arm_neon/int16x8x3_t
- arm_neon/veorq_u16
- arm_neon/vqdmulh_n_s16
- arm_neon/vhaddq_u8
- arm_neon/vpadal_u8
- arm_neon/vst2q_s16
- arm_neon/poly16x8x4_t
- arm_neon/int64x2_t
- arm_neon/vmull_s32
- arm_neon/vld4_lane_s32
- arm_neon/vst4q_p8
- arm_neon/vmlal_lane_u16
- arm_neon/vclz_u32
- arm_neon/vsliq_n_s8
- arm_neon/vmls_n_f32
- arm_neon/vmlsl_lane_s16
- arm_neon/vst4q_u32
- arm_neon/vld1q_lane_s16
- arm_neon/vst1q_f32
- arm_neon/vrshr_n_u8
- arm_neon/vst1q_s64
- arm_neon/vbslq_u32
- arm_neon/vset_lane_s8
- arm_neon/vdupq_lane_p16
- arm_neon/vtstq_s16
- arm_neon/vshl_n_s8
- arm_neon/vqrdmulhq_n_s16
- arm_neon/vget_high_f16
- arm_neon/vst4_lane_u32
- arm_neon/vraddhn_s16
- arm_neon/vmlsl_lane_s32
- arm_neon/vld3q_s32
- arm_neon/vsriq_n_u64
- arm_neon/vld4_dup_u8
- arm_neon/vld4q_s8
- arm_neon/vqmovn_s64
- arm_neon/vrev32q_p8
- arm_neon/vsliq_n_p8
- arm_neon/vzipq_s16
- arm_neon/vgetq_lane_s64
- arm_neon/vst4_p16
- arm_neon/vsubq_u16
- arm_neon/vrev64_s32
- armintr/_arm_uhadd8
- arm_neon/vornq_u16
- arm_neon/vst4_lane_s8
- arm_neon/vabd_s32
- arm_neon/vqrdmulhq_s16
- arm_neon/vqshlq_s32
- arm_neon/int64x2x4_t
- arm_neon/vset_lane_u16
- arm_neon/vrsra_n_s32
- arm_neon/vabdl_u16
- arm_neon/vsliq_n_s32
helpviewer_keywords:
- cl.exe compiler, intrinsics
- intrinsics, ARM
ms.assetid: d3d7dadd-7bd5-4508-8bff-371a66913e20
ms.openlocfilehash: 7a6020b4333c11f5581742e85ea16ce9c43e9dca
ms.sourcegitcommit: c123cc76bb2b6c5cde6f4c425ece420ac733bf70
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 04/14/2020
ms.locfileid: "81368229"
---
# <a name="arm-intrinsics"></a>Intr√≠nsecos ARM

O compilador Microsoft C++ (MSVC) disponibiliza os seguintes intr√≠nsecos na arquitetura ARM. Para obter mais informa√ß√µes sobre a ARM, consulte as se√ß√µes Ferramentas de Arquitetura e Desenvolvimento de Software do site [da ARM Developer Documentation.](https://developer.arm.com/docs)

## <a name="neon"></a><a name="top"></a>Neon

As extens√µes do conjunto de instru√ß√µes vetoriais NEON para ARM fornecem recursos SIMD (Single Instruction Multiple Data, dados m√∫ltiplos de instru√ß√£o que se assemelham aos dos conjuntos de instru√ß√µes vetoriais MMX e SSE que s√£o comuns aos processadores de arquitetura x86 e x64).

Intr√≠nsecos do NEON s√£o suportados, conforme fornecido no arquivo de cabe√ßalho `arm_neon.h`. O suporte msvc para intr√≠nsecas NEON se assemelha ao do compilador ARM, que est√° documentado no ap√™ndice G da cadeia de [ferramentas ARM Compiler, Vers√£o 4.1 Compiler Reference](https://go.microsoft.com/fwlink/p/?LinkId=251083) no site arm Infocenter.

A principal diferen√ßa entre o MSVC e o compilador `_ex` ARM √© `vldX` `vstX` que o MSVC adiciona variantes da carga vetorial e instru√ß√µes de armazenamento. As variantes `_ex` usam um par√¢metro adicional que especifica o alinhamento do argumento de ponteiro, mas que s√£o id√™nticas a suas n√£o `_ex` equivalentes.

## <a name="arm-specific-intrinsics-listing"></a><a name="A"></a>Listagem intr√≠nseca espec√≠fica da ARM

|Nome da fun√ß√£o|Instru√ß√£o|Prot√≥tipo da fun√ß√£o|
|-------------------|-----------------|------------------------|
|_arm_smlal|SMLAL|_arm_smlal __int64\__int64 _RdHiLo, int _Rn, int _Rm)|
|_arm_umlal|UMLAL|__int64 n√£o assinada _arm_umlal \_(_RdHiLo de _int64 n√£o assinado, _Rn int n√£o assinado, int _Rm n√£o assinado)|
|_arm_clz|CLZ|unsigned int _arm_clz(unsigned int _Rm)|
|_arm_qadd|QADD|int _arm_qadd(int _Rm, int _Rn)|
|_arm_qdadd|QDADD|int _arm_qdadd(int _Rm, int _Rn)|
|_arm_qdsub|QDSUB|int _arm_qdsub(int _Rm, int _Rn)|
|_arm_qsub|QSUB|int _arm_qsub(int _Rm, int _Rn)|
|_arm_smlabb|SMLABB|int _arm_smlabb(int _Rn, int _Rm, int _Ra)|
|_arm_smlabt|SMLABT|int _arm_smlabt(int _Rn, int _Rm, int _Ra)|
|_arm_smlatb|SMLATB|int _arm_smlatb(int _Rn, int _Rm, int _Ra)|
|_arm_smlatt|SMLATT|int _arm_smlatt(int _Rn, int _Rm, int _Ra)|
|_arm_smlalbb|SMLALBB|__int64 _arm_smlalbb\__RdHiLo _int64, int _Rn, int _Rm)|
|_arm_smlalbt|SMLALBT|__int64 _arm_smlalbt\__int64 _RdHiLo, _Rn int _Rm)|
|_arm_smlaltb|SMLALTB|__int64 _arm_smlaltb\__int64 _RdHiLo, int _Rn, int _Rm)|
|_arm_smlaltt|SMLALTT|__int64 _arm_smlaltt\__RdHiLo _int64, _Rn _Rm int.|
|_arm_smlawb|SMLAWB|int _arm_smlawb(int _Rn, int _Rm, int _Ra)|
|_arm_smlawt|SMLAWT|int _arm_smlawt(int _Rn, int _Rm, int _Ra)|
|_arm_smulbb|SMULBB|int _arm_smulbb(int _Rn, int _Rm)|
|_arm_smulbt|SMULBT|int _arm_smulbt(int _Rn, int _Rm)|
|_arm_smultb|SMULTB|int _arm_smultb(int _Rn, int _Rm)|
|_arm_smultt|SMULTT|int _arm_smultt(int _Rn, int _Rm)|
|_arm_smulwb|SMULWB|int _arm_smulwb(int _Rn, int _Rm)|
|_arm_smulwt|SMULWT|int _arm_smulwt(int _Rn, int _Rm)|
|_arm_sadd16|SADD16|int _arm_sadd16(int _Rn, int _Rm)|
|_arm_sadd8|SADD8|int _arm_sadd8(int _Rn, int _Rm)|
|_arm_sasx|SASX|int _arm_sasx(int _Rn, int _Rm)|
|_arm_ssax|SSAX|int _arm_ssax(int _Rn, int _Rm)|
|_arm_ssub16|SSUB16|int _arm_ssub16(int _Rn, int _Rm)|
|_arm_ssub8|SSUB8|int _arm_ssub8(int _Rn, int _Rm)|
|_arm_shadd16|SHADD16|int _arm_shadd16(int _Rn, int _Rm)|
|_arm_shadd8|SHADD8|int _arm_shadd8(int _Rn, int _Rm)|
|_arm_shasx|SHASX|int _arm_shasx(int _Rn, int _Rm)|
|_arm_shsax|SHSAX|int _arm_shsax(int _Rn, int _Rm)|
|_arm_shsub16|SHSUB16|int _arm_shsub16(int _Rn, int _Rm)|
|_arm_shsub8|SHSUB8|int _arm_shsub8(int _Rn, int _Rm)|
|_arm_qadd16|QADD16|int _arm_qadd16(int _Rn, int _Rm)|
|_arm_qadd8|QADD8|int _arm_qadd8(int _Rn, int _Rm)|
|_arm_qasx|QASX|int _arm_qasx(int _Rn, int _Rm)|
|_arm_qsax|QSAX|int _arm_qsax(int _Rn, int _Rm)|
|_arm_qsub16|QSUB16|int _arm_qsub16(int _Rn, int _Rm)|
|_arm_qsub8|QSUB8|int _arm_qsub8(int _Rn, int _Rm)|
|_arm_uadd16|UADD16|unsigned int _arm_uadd16(unsigned int _Rn, unsigned int _Rm)|
|_arm_uadd8|UADD8|unsigned int _arm_uadd8(unsigned int _Rn, unsigned int _Rm)|
|_arm_uasx|UASX|unsigned int _arm_uasx(unsigned int _Rn, unsigned int _Rm)|
|_arm_usax|USAX|unsigned int _arm_usax(unsigned int _Rn, unsigned int _Rm)|
|_arm_usub16|USUB16|unsigned int _arm_usub16(unsigned int _Rn, unsigned int _Rm)|
|_arm_usub8|USUB8|unsigned int _arm_usub8(unsigned int _Rn, unsigned int _Rm)|
|_arm_uhadd16|UHADD16|unsigned int _arm_uhadd16(unsigned int _Rn, unsigned int _Rm)|
|_arm_uhadd8|UHADD8|unsigned int _arm_uhadd8(unsigned int _Rn, unsigned int _Rm)|
|_arm_uhasx|UHASX|unsigned int _arm_uhasx(unsigned int _Rn, unsigned int _Rm)|
|_arm_uhsax|UHSAX|unsigned int _arm_uhsax(unsigned int _Rn, unsigned int _Rm)|
|_arm_uhsub16|UHSUB16|unsigned int _arm_uhsub16(unsigned int _Rn, unsigned int _Rm)|
|_arm_uhsub8|UHSUB8|unsigned int _arm_uhsub8(unsigned int _Rn, unsigned int _Rm)|
|_arm_uqadd16|UQADD16|unsigned int _arm_uqadd16(unsigned int _Rn, unsigned int _Rm)|
|_arm_uqadd8|UQADD8|unsigned int _arm_uqadd8(unsigned int _Rn, unsigned int _Rm)|
|_arm_uqasx|UQASX|unsigned int _arm_uqasx(unsigned int _Rn, unsigned int _Rm)|
|_arm_uqsax|UQSAX|unsigned int _arm_uqsax(unsigned int _Rn, unsigned int _Rm)|
|_arm_uqsub16|UQSUB16|unsigned int _arm_uqsub16(unsigned int _Rn, unsigned int _Rm)|
|_arm_uqsub8|UQSUB8|unsigned int _arm_uqsub8(unsigned int _Rn, unsigned int _Rm)|
|_arm_sxtab|SXTAB|int _arm_sxtab(int _Rn, int _Rm, unsigned int _Rotation)|
|_arm_sxtab16|SXTAB16|int _arm_sxtab16(int _Rn, int _Rm, unsigned int _Rotation)|
|_arm_sxtah|SXTAH|int _arm_sxtah(int _Rn, int _Rm, unsigned int _Rotation)|
|_arm_uxtab|UXTAB|unsigned int _arm_uxtab(unsigned int _Rn, unsigned int _Rm, unsigned int _Rotation)|
|_arm_uxtab16|UXTAB16|unsigned int _arm_uxta16b(unsigned int _Rn, unsigned int _Rm, unsigned int _Rotation)|
|_arm_uxtah|UXTAH|unsigned int _arm_uxtah(unsigned int _Rn, unsigned int _Rm, unsigned int _Rotation)|
|_arm_sxtb|SXTB|int _arm_sxtb(int _Rn, unsigned int _Rotation)|
|_arm_sxtb16|SXTB16|int _arm_sxtb16(int _Rn, unsigned int _Rotation)|
|_arm_sxth|SXTH|int _arm_sxth(int _Rn, unsigned int _Rotation)|
|_arm_uxtb|UXTB|unsigned int _arm_uxtb(unsigned int _Rn, unsigned int _Rotation)|
|_arm_uxtb16|UXTB16|unsigned int _arm_uxtb16(unsigned int _Rn, unsigned int _Rotation)|
|_arm_uxth|UXTH|unsigned int _arm_uxth(unsigned int _Rn, unsigned int _Rotation)|
|_arm_pkhbt|PKHBT|int _arm_pkhbt(int _Rn, int _Rm, unsigned int _Lsl_imm)|
|_arm_pkhtb|PKHTB|int _arm_pkhtb(int _Rn, int _Rm, unsigned int _Asr_imm)|
|_arm_usad8|USAD8|unsigned int _arm_usad8(unsigned int _Rn, unsigned int _Rm)|
|_arm_usada8|USADA8|unsigned int _arm_usada8(unsigned int _Rn, unsigned int _Rm, unsigned int _Ra)|
|_arm_ssat|SSAT|int _arm_ssat(unsigned int _Sat_imm, _int _Rn, _ARMINTR_SHIFT_T _Shift_type, unsigned int _Shift_imm)|
|_arm_usat|USAT|int _arm_usat(unsigned int _Sat_imm, _int _Rn, _ARMINTR_SHIFT_T _Shift_type, unsigned int _Shift_imm)|
|_arm_ssat16|SSAT16|int _arm_ssat16(unsigned int _Sat_imm, _int _Rn)|
|_arm_usat16|USAT16|int _arm_usat16(unsigned int _Sat_imm, _int _Rn)|
|_arm_rev|REVIS√ÉO|unsigned int _arm_rev(unsigned int _Rm)|
|_arm_rev16|REV16|unsigned int _arm_rev16(unsigned int _Rm)|
|_arm_revsh|REVSH|unsigned int _arm_revsh(unsigned int _Rm)|
|_arm_smlad|SMLAD|int _arm_smlad(int _Rn, int _Rm, int _Ra)|
|_arm_smladx|SMLADX|int _arm_smladx(int _Rn, int _Rm, int _Ra)|
|_arm_smlsd|SMLSD|int _arm_smlsd(int _Rn, int _Rm, int _Ra)|
|_arm_smlsdx|SMLSDX|int _arm_smlsdx(int _Rn, int _Rm, int _Ra)|
|_arm_smmla|SMMLA|int _arm_smmla(int _Rn, int _Rm, int _Ra)|
|_arm_smmlar|SMMLAR|int _arm_smmlar(int _Rn, int _Rm, int _Ra)|
|_arm_smmls|SMMLS|int _arm_smmls(int _Rn, int _Rm, int _Ra)|
|_arm_smmlsr|SMMLSR|int _arm_smmlsr(int _Rn, int _Rm, int _Ra)|
|_arm_smmul|SMMUL|int _arm_smmul(int _Rn, int _Rm)|
|_arm_smmulr|SMMULR|int _arm_smmulr(int _Rn, int _Rm)|
|_arm_smlald|SMLALD|__int64 _arm_smlald(_int64\__RdHiLo, int _Rn, int _Rm)|
|_arm_smlaldx|SMLALDX|_arm_smlaldx __int64\__int64 _RdHiLo, _Rn int _Rm)|
|_arm_smlsld|SMLSLD|__int64 _arm_smlsld\__RdHiLo _int64, _Rn _RdHiLo, int _Rm).|
|_arm_smlsldx|SMLSLDX|__int64 _arm_smlsldx\__int64 _RdHiLo, int _Rn, int _Rm)|
|_arm_smuad|SMUAD|int _arm_smuad(int _Rn, int _Rm)|
|_arm_smuadx|SMUADX|int _arm_muadxs(int _Rn, int _Rm)|
|_arm_smusd|SMUSD|int _arm_smusd(int _Rn, int _Rm)|
|_arm_smusdx|SMUSDX|int _arm_smusdx(int _Rn, int _Rm)|
|_arm_smull|SMULL|__int64 _arm_smull(int _Rn, int _Rm)|
|_arm_umull|UMULL|unsigned __int64 _arm_umull(unsigned int _Rn, unsigned int _Rm)|
|_arm_umaal|UMAAL|unsigned __int64 _arm_umaal(unsigned int _RdLo, unsigned int _RdHi, unsigned int _Rn, unsigned int _Rm)|
|_arm_bfc|BFC|unsigned int _arm_bfc(unsigned int _Rd, unsigned int _Lsb, unsigned int _Width)|
|_arm_bfi|BFI|unsigned int _arm_bfi(unsigned int _Rd, unsigned int _Rn, unsigned int _Lsb, unsigned int _Width)|
|_arm_rbit|RBIT|unsigned int _arm_rbit(unsigned int _Rm)|
|_arm_sbfx|SBFX|int _arm_sbfx(int _Rn, unsigned int _Lsb, unsigned int _Width)|
|_arm_ubfx|UBFX|unsigned int _arm_ubfx(unsigned int _Rn, unsigned int _Lsb, unsigned int _Width)|
|_arm_sdiv|SDIV|int _arm_sdiv(int _Rn, int _Rm)|
|_arm_udiv|UDIV|unsigned int _arm_udiv(unsigned int _Rn, unsigned int _Rm)|
|__cps|CPS|void __cps(unsigned int _Ops, unsigned int _Flags, unsigned int _Mode)|
|__dmb|DMB|void __dmb(unsigned int `_Type`)<br /><br /> Insere uma opera√ß√£o de barreira de mem√≥ria no fluxo de instru√ß√µes. O par√¢metro `_Type` especifica o tipo de restri√ß√£o que a barreira imp√µe.<br /><br /> Para obter mais informa√ß√µes sobre os tipos de restri√ß√µes que podem ser aplicadas, consulte [Restri√ß√µes de Barreira de Mem√≥ria](#BarrierRestrictions).|
|__dsb|DSB|void __dsb(unsigned int _Type)<br /><br /> Insere uma opera√ß√£o de barreira de mem√≥ria no fluxo de instru√ß√µes. O par√¢metro `_Type` especifica o tipo de restri√ß√£o que a barreira imp√µe.<br /><br /> Para obter mais informa√ß√µes sobre os tipos de restri√ß√µes que podem ser aplicadas, consulte [Restri√ß√µes de Barreira de Mem√≥ria](#BarrierRestrictions).|
|__isb|ISB|void __isb(unsigned int _Type)<br /><br /> Insere uma opera√ß√£o de barreira de mem√≥ria no fluxo de instru√ß√µes. O par√¢metro `_Type` especifica o tipo de restri√ß√£o que a barreira imp√µe.<br /><br /> Para obter mais informa√ß√µes sobre os tipos de restri√ß√µes que podem ser aplicadas, consulte [Restri√ß√µes de Barreira de Mem√≥ria](#BarrierRestrictions).|
|__emit||__emit anular (c√≥digo de _int32 n√£o assinado) \_<br /><br /> Insere uma instru√ß√£o especificada no fluxo de instru√ß√µes produzido pelo compilador.<br /><br /> O valor de `opcode` deve ser uma express√£o constante conhecida em tempo de compila√ß√£o. O tamanho de uma palavra de instru√ß√£o √© 16 bits e 16 bits mais significativos de `opcode` s√£o ignorados.<br /><br /> O compilador n√£o faz nenhuma tentativa `opcode` de interpretar o conte√∫do e n√£o garante um estado de CPU ou mem√≥ria antes que a instru√ß√£o inserida seja executada.<br /><br /> O compilador sup√µe que os estados de CPU e mem√≥ria s√£o inalterados depois que a instru√ß√£o inserida √© executada. Portanto, instru√ß√µes que mudam de estado podem ter um impacto prejudicial no c√≥digo normal gerado pelo compilador.<br /><br /> Por essa raz√£o, use `emit` apenas para inserir instru√ß√µes que afetam um estado de CPU que o compilador normalmente n√£o processa ‚Äî por exemplo, o estado do coprocessador ‚Äî ou para implementar fun√ß√µes declaradas usando `declspec(naked)`.|
|__hvc|HVC|unsigned int __hvc(unsigned int, ...)|
|__iso_volatile_load16||_iso_volatile_load16 \___int16 (_int16 \_ \*vol√°teis const)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_load32||_iso_volatile_load32 \___int32 (_int32 \_ \*vol√°teis const)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_load64||_iso_volatile_load64 \___int64 (_int64 \_ \*vol√°teis const)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_load8||_iso_volatile_load8 \___int8 (_int8 \_ \*vol√°teis const)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_store16||__iso_volatile_store16 vazio \_ \*(_int16 \_vol√°til , _int16)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_store32||__iso_volatile_store32 vazio \_ \*(_int32 \_vol√°teis , _int32)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_store64||__iso_volatile_store64 vazio \_ \*(_int64 \_vol√°teis , _int64)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__iso_volatile_store8||__iso_volatile_store8 vazio \_ \*(_int8 \_vol√°teis , _int8)<br /><br /> Para obter mais informa√ß√µes, consulte [intr√≠nsecos __iso_volatile_load/loja](#IsoVolatileLoadStore).|
|__ldrexd|LDREXD|_ldrexd \___int64 (_int64 \_ \*vol√°teis const)|
|__prefetch|PLD|vazio \___cdecl _prefetch (vazio \*const)<br /><br /> Fornece uma dica de mem√≥ria de `PLD` ao sistema de que a mem√≥ria que est√° no endere√ßo especificado ou pr√≥ximo a ele pode ser acessada. Alguns sistemas podem optar por otimizar para esse padr√£o de acesso de mem√≥ria para aumentar o desempenho de runtime. No entanto, do ponto de vista da linguagem C++, a fun√ß√£o n√£o tem efeito observ√°vel e pode n√£o ter nenhuma a√ß√£o.|
|__rdpmccntr64||_rdpmccntr64 __int64 \_n√£o assinados (vazio)|
|__sev|SETE|void __sev(void)|
|__static_assert||vazio __static_assert(int, const char \*)|
|__swi|SVC|unsigned int __swi(unsigned int, ...)|
|__trap|BKPT|int __trap (int...)|
|__wfe|WFE|void __wfe(void)|
|__wfi|WFI|void __wfi(void)|
|_AddSatInt|QADD|int _AddSatInt(int, int)|
|_CopyDoubleFromInt64||_CopyDoubleFromInt64 duplo\_(_int64)|
|_CopyFloatFromInt32||_CopyFloatFromInt32 flutuante\_(_int32)|
|_CopyInt32FromFloat||__int32 _CopyInt32FromFloat(float)|
|_CopyInt64FromDouble||__int64 _CopyInt64FromDouble(double)|
|_CountLeadingOnes||unsigned int _CountLeadingOnes(unsigned long)|
|_CountLeadingOnes64||_CountLeadingOnes64 int n√£o assinado \_(_int64 n√£o assinado)|
|_CountLeadingSigns||unsigned int _CountLeadingSigns(long)|
|_CountLeadingSigns64||int _CountLeadingSigns64 n√£o\_assinado (_int64)|
|_CountLeadingZeros||unsigned int _CountLeadingZeros(unsigned long)|
|_CountLeadingZeros64||_CountLeadingZeros64 int n√£o assinado \_(_int64 n√£o assinado)|
|_CountOneBits||unsigned int _CountOneBits(unsigned long)|
|_CountOneBits64||int _CountOneBits64 n√£o assinado \_(_int64 n√£o assinado)|
|_DAddSatInt|QDADD|int _DAddSatInt(int, int)|
|_DSubSatInt|QDSUB|int _DSubSatInt(int, int)|
|_isunordered||int _isunordered(double, double)|
|_isunorderedf||int _isunorderedf(float, float)|
|_MoveFromCoprocessor|MRC|unsigned int _MoveFromCoprocessor(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int)<br /><br /> L√™ dados de um coprocessador de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador. Para obter mais informa√ß√µes, consulte [_MoveFromCoprocessor, _MoveFromCoprocessor2](#MoveFromCo).|
|_MoveFromCoprocessor2|MRC2|unsigned int _MoveFromCoprocessor2(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int)<br /><br /> L√™ dados de um coprocessador de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador. Para obter mais informa√ß√µes, consulte [_MoveFromCoprocessor, _MoveFromCoprocessor2](#MoveFromCo).|
|_MoveFromCoprocessor64|MRRC|unsigned __int64 _MoveFromCoprocessor64(unsigned int, unsigned int, unsigned int)<br /><br /> L√™ dados de um coprocessador de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador. Para obter mais informa√ß√µes, consulte [_MoveFromCoprocessor64](#MoveFromCo64).|
|_MoveToCoprocessor|MCR|void _MoveToCoprocessor(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int)<br /><br /> L√™ dados de um coprocessador de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador. Para obter mais informa√ß√µes, consulte [_MoveToCoprocessor, _MoveToCoprocessor2](#MoveToCo).|
|_MoveToCoprocessor2|MCR2|void _MoveToCoprocessor2(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int)<br /><br /> L√™ dados de um coprocessador de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador. Para obter mais informa√ß√µes, consulte [_MoveToCoprocessor, _MoveToCoprocessor2](#MoveToCo).|
|_MoveToCoprocessor64|MCRR|vazio _MoveToCoprocessor64 (_int64 n√£o assinado, \_int n√£o assinado, int n√£o assinado, int n√£o assinado)<br /><br /> L√™ dados de um coprocessador de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador. Para obter mais informa√ß√µes, consulte [_MoveToCoprocessor64](#MoveToCo64).|
|_MulHigh||long _MulHigh(long, long)|
|_MulUnsignedHigh||unsigned long _MulUnsignedHigh(unsigned long, unsigned long)|
|_ReadBankedReg|MRS|int _ReadBankedReg (int reg)|
|_ReadStatusReg|MRS|int _ReadStatusReg(int)|
|_SubSatInt|QSUB|int _SubSatInt(int, int)|
|_WriteBankedReg|MSR|void _WriteBankedReg(int _Value, int _Reg)|
|_WriteStatusReg|MSR|void _WriteStatusReg(int, int, int)|

[[Voltar ao topo](#top)]

### <a name="memory-barrier-restrictions"></a><a name="BarrierRestrictions"></a>Restri√ß√µes da barreira de mem√≥ria

As fun√ß√µes intr√≠nsecas `__dmb` (barreira de mem√≥ria de dados), `__dsb` (barreira de sincroniza√ß√£o de dados) e `__isb` (barreira de sincroniza√ß√£o de instru√ß√µes) usam os seguintes valores predefinidos para especificar a restri√ß√£o da barreira de mem√≥ria em termos do dom√≠nio de compartilhamento e do tipo de acesso que s√£o afetados pela opera√ß√£o.

|Valor de restri√ß√£o|Descri√ß√£o|
|-----------------------|-----------------|
|_ARM_BARRIER_SY|Sistema completo, leituras e grava√ß√µes.|
|_ARM_BARRIER_ST|Sistema completo, somente grava√ß√µes.|
|_ARM_BARRIER_ISH|Compartilh√°veis internos, leituras e grava√ß√µes.|
|_ARM_BARRIER_ISHST|Compartilh√°veis internos, somente grava√ß√µes.|
|_ARM_BARRIER_NSH|N√£o compartilh√°veis, leituras e grava√ß√µes.|
|_ARM_BARRIER_NSHST|N√£o compartilh√°veis, somente grava√ß√µes.|
|_ARM_BARRIER_OSH|Compartilh√°veis externos, leituras e grava√ß√µes.|
|_ARM_BARRIER_OSHST|Compartilh√°veis externos, somente grava√ß√µes.|

Para o intr√≠nseco `__isb`, a √∫nica restri√ß√£o que √© v√°lida no momento √© _ARM_BARRIER_SY; todos os outros valores s√£o reservados pela arquitetura.

### <a name="__iso_volatile_loadstore-intrinsics"></a><a name="IsoVolatileLoadStore"></a>intr√≠nseca de __iso_volatile_load/loja

Essas fun√ß√µes intr√≠nsecas executam explicitamente cargas e lojas que n√£o est√£o sujeitas a otimiza√ß√µes de compiladores.

```C
__int16 __iso_volatile_load16(const volatile __int16 * Location);
__int32 __iso_volatile_load32(const volatile __int32 * Location);
__int64 __iso_volatile_load64(const volatile __int64 * Location);
__int8 __iso_volatile_load8(const volatile __int8 * Location);

void __iso_volatile_store16(volatile __int16 * Location, __int16 Value);
void __iso_volatile_store32(volatile __int32 * Location, __int32 Value);
void __iso_volatile_store64(volatile __int64 * Location, __int64 Value);
void __iso_volatile_store8(volatile __int8 * Location, __int8 Value);
```

#### <a name="parameters"></a>Par√¢metros

*Localiza√ß√£o*\
O endere√ßo de um local de mem√≥ria para ler ou gravar.

*Valor*\
O valor para escrever no local de mem√≥ria especificado (apenas intr√≠nsecas de armazenamento).

#### <a name="return-value-load-intrinsics-only"></a>Valor de retorno (somente intr√≠nsecos √† carga)

O valor do local da mem√≥ria √© especificado por `Location`.

#### <a name="remarks"></a>Coment√°rios

Voc√™ pode `__iso_volatile_load8/16/32/64` usar `__iso_volatile_store8/16/32/64` os intr√≠nsecos para executar explicitamente acessos de mem√≥ria que n√£o est√£o sujeitos a otimiza√ß√µes de compiladores. O compilador n√£o pode remover, sintetizar ou alterar a ordem relativa dessas opera√ß√µes, mas n√£o gera barreiras impl√≠citas de mem√≥ria de hardware. Portanto, o hardware ainda pode reorganizar os acessos de mem√≥ria observ√°veis entre v√°rios threads. Mais precisamente, esses intr√≠nsecos s√£o equivalentes √†s seguintes express√µes compiladas em **/vol√°til:iso**.

```cpp
int a = __iso_volatile_load32(p);    // equivalent to: int a = *(const volatile __int32*)p;
__iso_volatile_store32(p, a);        // equivalent to: *(volatile __int32*)p = a;
```

Observe que o intr√≠nseco usa ponteiros vol√°teis para acomodar vari√°veis vol√°teis. No entanto, n√£o h√° nenhuma exig√™ncia ou recomenda√ß√£o para usar ponteiros vol√°teis como argumentos. A sem√¢ntica dessas opera√ß√µes √© exatamente a mesma se um tipo regular, n√£o vol√°til, for usado.

Para obter mais informa√ß√µes sobre o argumento **/vol√°til:iso** command-line, consulte [/vol√°til (interpreta√ß√£o vol√°til de palavras-chave)](../build/reference/volatile-volatile-keyword-interpretation.md).

### <a name="_movefromcoprocessor-_movefromcoprocessor2"></a><a name="MoveFromCo"></a>_MoveFromCoprocessor _MoveFromCoprocessor2

Essas fun√ß√µes intr√≠nsecas leem dados de coprocessadores de ARM usando instru√ß√µes de transfer√™ncia de dados de coprocessador.

```C
int _MoveFromCoprocessor(
      unsigned int coproc,
      unsigned int opcode1,
      unsigned int crn,
      unsigned int crm,
      unsigned int opcode2
);

int _MoveFromCoprocessor2(
      unsigned int coproc,
      unsigned int opcode1,
      unsigned int crn,
      unsigned int crm,
      unsigned int opcode2
);
```

#### <a name="parameters"></a>Par√¢metros

*coproc*\
N√∫mero de coprocessador no intervalo de 0 a 15.

*opcode1*\
C√≥digo operacional espec√≠fico de coprocessador no intervalo de 0 a 7

*Crn*\
N√∫mero de registro do coprocessador, no intervalo de 0 a 15, que especifica o primeiro operando da instru√ß√£o.

*Crm*\
N√∫mero de registro do coprocessador no intervalo de 0 a 15, que especifica uma fonte adicional ou operando de destino.

*opcode2*\
C√≥digo operacional adicional espec√≠fico de coprocessador no intervalo de 0 a 7.

#### <a name="return-value"></a>Valor retornado

O valor lido do coprocessador.

#### <a name="remarks"></a>Coment√°rios

Os valores de todos os cinco par√¢metros do intr√≠nseco devem ser express√µes constantes que s√£o conhecidas no momento da compila√ß√£o.

`_MoveFromCoprocessor` usa a instru√ß√£o MRC; `_MoveFromCoprocessor2` usa MRC2. Os par√¢metros correspondem a campos de bits codificados diretamente na palavra de instru√ß√£o. A interpreta√ß√£o dos par√¢metros depende do coprocessador. Para obter mais informa√ß√µes, consulte o manual do coprocessador em quest√£o.

### <a name="_movefromcoprocessor64"></a><a name="MoveFromCo64"></a>_MoveFromCoprocessor64

L√™ dados de coprocessadores de ARM usando as instru√ß√µes de transfer√™ncia de dados do coprocessador.

```C
unsigned __int64 _MoveFromCoprocessor64(
      unsigned int coproc,
      unsigned int opcode1,
      unsigned int crm,
);
```

#### <a name="parameters"></a>Par√¢metros

*coproc*\
N√∫mero de coprocessador no intervalo de 0 a 15.

*opcode1*\
C√≥digo operacional espec√≠fico de coprocessador no intervalo de 0 a 15.

*Crm*\
N√∫mero de registro do coprocessador no intervalo de 0 a 15, que especifica uma fonte adicional ou operando de destino.

**Valor de retorno**

O valor lido do coprocessador.

#### <a name="remarks"></a>Coment√°rios

Os valores dos tr√™s par√¢metros do intr√≠nseco devem ser express√µes constantes que s√£o conhecidas no momento da compila√ß√£o.

`_MoveFromCoprocessor64` usa a instru√ß√£o MRRC. Os par√¢metros correspondem a campos de bits codificados diretamente na palavra de instru√ß√£o. A interpreta√ß√£o dos par√¢metros depende do coprocessador. Para obter mais informa√ß√µes, consulte o manual do coprocessador em quest√£o.

### <a name="_movetocoprocessor-_movetocoprocessor2"></a><a name="MoveToCo"></a>_MoveToCoprocessor _MoveToCoprocessor2

Essas fun√ß√µes intr√≠nsecas gravam dados nos coprocessadores de ARM usando instru√ß√µes de transfer√™ncia de dados de coprocessador.

```C
void _MoveToCoprocessor(
      unsigned int value,
      unsigned int coproc,
      unsigned int opcode1,
      unsigned int crn,
      unsigned int crm,
      unsigned int opcode2
);

void _MoveToCoprocessor2(
      unsigned int value,
      unsigned int coproc,
      unsigned int opcode1,
      unsigned int crn,
      unsigned int crm,
      unsigned int opcode2
);
```

#### <a name="parameters"></a>Par√¢metros

*Valor*\
O valor a ser gravado no coprocessador.

*coproc*\
N√∫mero de coprocessador no intervalo de 0 a 15.

*opcode1*\
C√≥digo operacional espec√≠fico de coprocessador no intervalo de 0 a 7.

*Crn*\
N√∫mero de registro do coprocessador, no intervalo de 0 a 15, que especifica o primeiro operando da instru√ß√£o.

*Crm*\
N√∫mero de registro do coprocessador no intervalo de 0 a 15, que especifica uma fonte adicional ou operando de destino.

*opcode2*\
C√≥digo operacional adicional espec√≠fico de coprocessador no intervalo de 0 a 7.

#### <a name="return-value"></a>Valor retornado

Nenhum.

#### <a name="remarks"></a>Coment√°rios

Os valores `coproc` `opcode1`dos `crn` `crm`par√¢metros `opcode2` intr√≠nsecos devem ser express√µes constantes que s√£o conhecidas na √©poca da compila√ß√£o.

`_MoveToCoprocessor` usa a instru√ß√£o MCR; `_MoveToCoprocessor2` usa MCR2. Os par√¢metros correspondem a campos de bits codificados diretamente na palavra de instru√ß√£o. A interpreta√ß√£o dos par√¢metros depende do coprocessador. Para obter mais informa√ß√µes, consulte o manual do coprocessador em quest√£o.

### <a name="_movetocoprocessor64"></a><a name="MoveToCo64"></a>_MoveToCoprocessor64

Essas fun√ß√µes intr√≠nsecas gravam dados nos coprocessadores de ARM usando instru√ß√µes de transfer√™ncia de dados de coprocessador.

```
void _MoveFromCoprocessor64(
      unsigned __int64 value,
      unsigned int coproc,
      unsigned int opcode1,
      unsigned int crm,
);
```

#### <a name="parameters"></a>Par√¢metros

*coproc*\
N√∫mero de coprocessador no intervalo de 0 a 15.

*opcode1*\
C√≥digo operacional espec√≠fico de coprocessador no intervalo de 0 a 15.

*Crm*\
N√∫mero de registro do coprocessador no intervalo de 0 a 15, que especifica uma fonte adicional ou operando de destino.

#### <a name="return-value"></a>Valor retornado

Nenhum.

#### <a name="remarks"></a>Coment√°rios

Os valores `coproc` `opcode1`do `crm` , e par√¢metros do intr√≠nseco devem ser express√µes constantes que s√£o conhecidas na √©poca da compila√ß√£o.

`_MoveFromCoprocessor64` usa a instru√ß√£o MRRC. Os par√¢metros correspondem a campos de bits codificados diretamente na palavra de instru√ß√£o. A interpreta√ß√£o dos par√¢metros depende do coprocessador. Para obter mais informa√ß√µes, consulte o manual do coprocessador em quest√£o.

## <a name="arm-support-for-intrinsics-from-other-architectures"></a><a name="I"></a>Suporte ARM para Intr√≠nsecas de Outras Arquiteturas

A tabela a seguir lista intr√≠nsecos de outras arquiteturas que s√£o suportados em plataformas ARM. Onde o comportamento de um intr√≠nsecos no ARM difere de seu comportamento em outras arquiteturas de hardware, detalhes adicionais s√£o observados.

|Nome da fun√ß√£o|Prot√≥tipo da fun√ß√£o|
|-------------------|------------------------|
|__assume|void __assume(int)|
|__code_seg|__code_seg anular (const char) \*|
|__debugbreak|vazio \___cdecl _debugbreak (vazio)|
|__fastfail|__declspec (sem \_retorno) _fastfail nulo (int n√£o assinado)|
|__nop|anular __nop(vazio) **Nota:** Nas plataformas ARM, essa fun√ß√£o gera uma instru√ß√£o NOP se uma for implementada na arquitetura de destino; caso contr√°rio, uma instru√ß√£o alternativa que n√£o altera o estado do `MOV r8, r8`programa ou CPU √© gerada ‚Äî por exemplo, . √â funcionalmente equivalente ao \__nop intr√≠nseco para outras arquiteturas de hardware. Como uma instru√ß√£o que n√£o tem efeito sobre o estado do programa ou CPU pode ser ignorada pela arquitetura de destino como uma otimiza√ß√£o, a instru√ß√£o n√£o necessariamente consome ciclos de CPU. Portanto, n√£o use \_o _nop intr√≠nseco para manipular o tempo de execu√ß√£o de uma seq√º√™ncia de c√≥digo, a menos que voc√™ esteja certo sobre como a CPU se comportar√°. Em vez disso, \_voc√™ pode usar o _nop intr√≠nseco para alinhar a pr√≥xima instru√ß√£o a um endere√ßo de limite espec√≠fico de 32 bits.|
|__yield|anular __yield(vazio) **Nota:** Nas plataformas ARM, essa fun√ß√£o gera a instru√ß√£o YIELD, que indica que o segmento est√° executando uma tarefa que pode ser temporariamente suspensa da execu√ß√£o ‚Äî por exemplo, um spinlock ‚Äî sem afetar negativamente o programa. Ele permite que a CPU execute outras tarefas durante os ciclos de execu√ß√£o que de outra forma seriam desperdi√ßados.|
|_AddressOfReturnAddress|vazio \* _AddressOfReturnAddress (vazio)|
|_BitScanForward|_BitScanForward de char n√£o \* assinado (_Index longo sem assinatura, _Mask longo sem assinatura)|
|_BitScanReverse|char _BitScanReverse n√£o assinado \* (_Index longo sem assinatura, _Mask longo sem assinatura)|
|_bittest|char sem assinatura _bittest \*(const longo, longo)|
|_bittestandcomplement|char n√£o assinado \*_bittestandcomplement (longo, longo)|
|_bittestandreset|char n√£o assinado \*_bittestandreset (longo, longo)|
|_bittestandset|char n√£o assinado \*_bittestandset (longo, longo)|
|_byteswap_uint64|__int64 \_sem assinatura _cdecl \__byteswap_uint64 (_int64 n√£o assinado)|
|_byteswap_ulong|unsigned long __cdecl _byteswap_ulong(unsigned long)|
|_byteswap_ushort|unsigned short __cdecl _byteswap_ushort(unsigned short)|
|_disable|anular __cdecl _disable (vazio) **Nota:** Nas plataformas ARM, essa fun√ß√£o gera a instru√ß√£o CPSID; s√≥ est√° dispon√≠vel como intr√≠nseco.|
|_enable|anular __cdecl _enable (vazio) **Nota:** Nas plataformas ARM, essa fun√ß√£o gera a instru√ß√£o CPSIE; s√≥ est√° dispon√≠vel como intr√≠nseco.|
|_lrotl|unsigned long __cdecl _lrotl(unsigned long, int)|
|_lrotr|unsigned long __cdecl _lrotr(unsigned long, int)|
|_ReadBarrier|void _ReadBarrier(void)|
|_ReadWriteBarrier|void _ReadWriteBarrier(void)|
|_ReturnAddress|vazio \* _ReturnAddress (vazio)|
|_rotl|unsigned int __cdecl _rotl(unsigned int _Value, int _Shift)|
|_rotl16|unsigned short _rotl16(unsigned short _Value, unsigned char _Shift)|
|_rotl64|_rotl64 de \__cdecl __int64 \_n√£o assinados (_Value _int64 n√£o assinado, _Shift int)|
|_rotl8|unsigned char _rotl8(unsigned char _Value, unsigned char _Shift)|
|_rotr|unsigned int __cdecl _rotr(unsigned int _Value, int _Shift)|
|_rotr16|unsigned short _rotr16(unsigned short _Value, unsigned char _Shift)|
|_rotr64|__int64 \__rotr64 _cdecl _rotr64 \_sem assinatura (_Value _int64 n√£o assinados, int _Shift)|
|_rotr8|unsigned char _rotr8(unsigned char _Value, unsigned char _Shift)|
|_setjmpex|int __cdecl _setjmpex(jmp_buf)|
|_WriteBarrier|void _WriteBarrier(void)|

[[Voltar ao topo](#top)]

## <a name="interlocked-intrinsics"></a>Intr√≠nsecos interbloqueados

Intr√≠nsecos sincronizados s√£o um conjunto de intr√≠nsecos usados para executar opera√ß√µes at√¥micas de leitura, grava√ß√£o e altera√ß√£o. Alguns deles s√£o comuns a todas as plataformas. Eles est√£o listados separadamente aqui porque h√° um grande n√∫mero deles, mas como suas defini√ß√µes s√£o principalmente redundantes, √© mais f√°cil pensar sobre eles em termos gerais. Seus nomes podem ser usados para gerar comportamentos exatos.

A tabela a seguir resume o suporte ARM a intr√≠nsecos sincronizados n√£o bittest. Cada c√©lula da tabela corresponde a um nome que √© derivado acrescentando o nome da opera√ß√£o na c√©lula mais √† esquerda da linha e o nome do tipo na c√©lula superior da coluna para `_Interlocked`. Por exemplo, a c√©lula no `Xor` cruzamento `8` da linha `_InterlockedXor8` e da coluna corresponde e √© totalmente suportada. A maioria das fun√ß√µes com suporte oferece estes sufixos opcionais: `_acq`, `_rel`, e `_nf`. O sufixo `_acq` indica uma sem√¢ntica "acquire" e o sufixo `_rel` indica uma sem√¢ntica uma "release". O `_nf` sufixo "sem cerca" √© exclusivo do ARM e √© discutido na pr√≥xima se√ß√£o.

||8|16|32|64|P|
|-|-------|--------|--------|--------|-------|
|Adicionar|Nenhum|Nenhum|Completo|Completo|Nenhum|
|And|Completo|Completo|Completo|Completo|Nenhum|
|CompareExchange|Completo|Completo|Completo|Completo|Completo|
|Decremento|Nenhum|Completo|Completo|Completo|Nenhum|
|Exchange|Parcial|Parcial|Parcial|Parcial|Parcial|
|ExchangeAdd|Completo|Completo|Completo|Completo|Nenhum|
|Incremento|Nenhum|Completo|Completo|Completo|Nenhum|
|Ou|Completo|Completo|Completo|Completo|Nenhum|
|Xor|Completo|Completo|Completo|Completo|Nenhum|

Chave:

- **Completo:** suporta formas simples, `_acq` `_rel`e `_nf` formas.

- **Parcial**: suporta `_acq`simples, `_nf` e formas.

- **Nenhum**: N√£o suportado

### <a name="_nf-no-fence-suffix"></a><a name="nf_suffix"></a>sufixo _nf (sem cerca)

O `_nf` sufixo "sem cerca" indica que a opera√ß√£o n√£o se comporta como qualquer tipo de `_acq`barreira `_rel`de mem√≥ria, em contraste com as outras tr√™s formas (simples, e ), que se comportam como uma esp√©cie de barreira. Um poss√≠vel uso `_nf` dos formul√°rios √© manter um contador de estat√≠sticas que √© atualizado por v√°rios segmentos ao mesmo tempo, mas cujo valor n√£o √© usado de outra forma enquanto v√°rios segmentos est√£o sendo executados.

### <a name="list-of-interlocked-intrinsics"></a>Lista de intr√≠nsecos interbloqueados

|Nome da fun√ß√£o|Prot√≥tipo da fun√ß√£o|
|-------------------|------------------------|
|_InterlockedAdd|_InterlockedAdd longo (longo _volatile, \*longo)|
|_InterlockedAdd64|__int64\__InterlockedAdd64(_int64 \* \_vol√°til , _int64)|
|_InterlockedAdd64_acq|__int64 _InterlockedAdd64_acq\__int64 \* \__int64|
|_InterlockedAdd64_nf|_InterlockedAdd64_nf\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedAdd64_rel|_InterlockedAdd64_rel\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedAdd_acq|longo _InterlockedAdd_acq (longo vol√°til, \*longo)|
|_InterlockedAdd_nf|longo _InterlockedAdd_nf (longo vol√°til, \*longo)|
|_InterlockedAdd_rel|longo _InterlockedAdd_rel (longo vol√°til, \*longo)|
|_InterlockedAnd|longo_InterlockedAnd (longo \*vol√°til, longo)|
|_InterlockedAnd16|_InterlockedAnd16 curto (curto vol√°til, \*curto)|
|_InterlockedAnd16_acq|_InterlockedAnd16_acq curto (curto vol√°til, \*curto)|
|_InterlockedAnd16_nf|_InterlockedAnd16_nf curto (curto vol√°til, \*curto)|
|_InterlockedAnd16_rel|_InterlockedAnd16_rel curto (curto vol√°til, \*curto)|
|_InterlockedAnd64|_InterlockedAnd64\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedAnd64_acq|_InterlockedAnd64_acq\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedAnd64_nf|_InterlockedAnd64_nf\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedAnd64_rel|__int64\__InterlockedAnd64_rel(_int64 \* \_vol√°til , _int64)|
|_InterlockedAnd8|char _InterlockedAnd8 (char vol√°til, \*char)|
|_InterlockedAnd8_acq|char _InterlockedAnd8_acq (char vol√°til, \*char)|
|_InterlockedAnd8_nf|char _InterlockedAnd8_nf (char vol√°til, \*char)|
|_InterlockedAnd8_rel|char _InterlockedAnd8_rel (char vol√°til, \*char)|
|_InterlockedAnd_acq|longo _InterlockedAnd_acq (longo vol√°til, \*longo)|
|_InterlockedAnd_nf|longo _InterlockedAnd_nf (longo vol√°til, \*longo)|
|_InterlockedAnd_rel|longo _InterlockedAnd_rel (longo vol√°til, \*longo)|
|_InterlockedCompareExchange|longo __cdecl _InterlockedCompareExchange \*(longo vol√°til, longo, longo)|
|_InterlockedCompareExchange16|_InterlockedCompareExchange16 curto (curto vol√°til, \*curto, curto)|
|_InterlockedCompareExchange16_acq|_InterlockedCompareExchange16_acq curto (curto vol√°til, \*curto, curto)|
|_InterlockedCompareExchange16_nf|_InterlockedCompareExchange16_nf curto (curto vol√°til, \*curto, curto)|
|_InterlockedCompareExchange16_rel|_InterlockedCompareExchange16_rel curto (curto vol√°til, \*curto, curto)|
|_InterlockedCompareExchange64|_InterlockedCompareExchange64 __int64\__int64 \* \__int64, \__int64)|
|_InterlockedCompareExchange64_acq|_InterlockedCompareExchange64_acq\___int64(_int64 \* \_vol√°til \_, _int64, _int64)|
|_InterlockedCompareExchange64_nf|__int64 _InterlockedCompareExchange64_nf\__int64 \* \__int64 \__int64|
|_InterlockedCompareExchange64_rel|__int64\__InterlockedCompareExchange64_rel( \*_int64 \_vol√°til, _int64, \__int64)|
|_InterlockedCompareExchange8|char _InterlockedCompareExchange8 (char vol√°til, \*char, char)|
|_InterlockedCompareExchange8_acq|char _InterlockedCompareExchange8_acq (char vol√°til, \*char, char)|
|_InterlockedCompareExchange8_nf|char _InterlockedCompareExchange8_nf (char vol√°til, \*char, char)|
|_InterlockedCompareExchange8_rel|char _InterlockedCompareExchange8_rel (char vol√°til, \*char, char)|
|_InterlockedCompareExchangePointer|vazio \* _InterlockedCompareExchangePointer \* (vazio \* \*vol√°til, \*vazio, vazio)|
|_InterlockedCompareExchangePointer_acq|vazio \* _InterlockedCompareExchangePointer_acq \* (vazio \* \*vol√°til, \*vazio, vazio)|
|_InterlockedCompareExchangePointer_nf|vazio \* _InterlockedCompareExchangePointer_nf \* (vazio \* \*vol√°til, \*vazio, vazio)|
|_InterlockedCompareExchangePointer_rel|vazio \* _InterlockedCompareExchangePointer_rel \* (vazio \* \*vol√°til, \*vazio, vazio)|
|_InterlockedCompareExchange_acq|longo_InterlockedCompareExchange_acq (longo \*vol√°til, longo, longo)|
|_InterlockedCompareExchange_nf|longo _InterlockedCompareExchange_nf (longo vol√°til, \*longo, longo)|
|_InterlockedCompareExchange_rel|longo _InterlockedCompareExchange_rel (longo vol√°til, \*longo, longo)|
|_InterlockedDecrement|_InterlockedDecrement de __cdecl \*longo (longo vol√°til)|
|_InterlockedDecrement16|_InterlockedDecrement16 curto (curto vol√°til) \*|
|_InterlockedDecrement16_acq|_InterlockedDecrement16_acq curto (curto vol√°til) \*|
|_InterlockedDecrement16_nf|curto _InterlockedDecrement16_nf (curto vol√°til) \*|
|_InterlockedDecrement16_rel|_InterlockedDecrement16_rel curto (curto vol√°til) \*|
|_InterlockedDecrement64|__int64 _InterlockedDecrement64(\_ \*_int64 vol√°til)|
|_InterlockedDecrement64_acq|_InterlockedDecrement64_acq\___int64(_int64 \*vol√°til)|
|_InterlockedDecrement64_nf|__int64 _InterlockedDecrement64_nf(\_ \*_int64 vol√°til)|
|_InterlockedDecrement64_rel|_InterlockedDecrement64_rel __int64(\_ \*_int64 vol√°til)|
|_InterlockedDecrement_acq|longo _InterlockedDecrement_acq (longo vol√°til) \*|
|_InterlockedDecrement_nf|_InterlockedDecrement_nf longo (longo vol√°til) \*|
|_InterlockedDecrement_rel|longo _InterlockedDecrement_rel (longo vol√°til) \*|
|_InterlockedExchange|_InterlockedExchange __cdecl longo \* (_Target vol√°teis longos, longos)|
|_InterlockedExchange16|_InterlockedExchange16 curto (_Target vol√°til \* curto, curto)|
|_InterlockedExchange16_acq|_InterlockedExchange16_acq curto (_Target vol√°til \* curto, curto)|
|_InterlockedExchange16_nf|_InterlockedExchange16_nf curto (_Target vol√°til \* curto, curto)|
|_InterlockedExchange64|_InterlockedExchange64 __int64(\_ \* _int64 \__Target vol√°til, _int64)|
|_InterlockedExchange64_acq|__int64 _InterlockedExchange64_acq\__int64 \* _Target \_vol√°til, _int64)|
|_InterlockedExchange64_nf|__int64 _InterlockedExchange64_nf\__int64 \* _Target \_vol√°til, _int64)|
|_InterlockedExchange8|char _InterlockedExchange8 (char _Target vol√°til, \* char)|
|_InterlockedExchange8_acq|char _InterlockedExchange8_acq (char vol√°til \* _Target, char)|
|_InterlockedExchange8_nf|char _InterlockedExchange8_nf (char _Target vol√°til, \* char)|
|_InterlockedExchangeAdd|longo __cdecl _InterlockedExchangeAdd \*(longo vol√°til, longo)|
|_InterlockedExchangeAdd16|_InterlockedExchangeAdd16 curto (curto vol√°til, \*curto)|
|_InterlockedExchangeAdd16_acq|_InterlockedExchangeAdd16_acq curto (curto vol√°til, \*curto)|
|_InterlockedExchangeAdd16_nf|_InterlockedExchangeAdd16_nf curto (curto vol√°til, \*curto)|
|_InterlockedExchangeAdd16_rel|_InterlockedExchangeAdd16_rel curto (curto vol√°til, \*curto)|
|_InterlockedExchangeAdd64|_InterlockedExchangeAdd64 __int64(\_ \*_int64 \_vol√°til , _int64)|
|_InterlockedExchangeAdd64_acq|_InterlockedExchangeAdd64_acq __int64(\_ \*_int64 \_vol√°til , _int64)|
|_InterlockedExchangeAdd64_nf|__int64\__InterlockedExchangeAdd64_nf(_int64 \* \_vol√°til , _int64)|
|_InterlockedExchangeAdd64_rel|__int64 _InterlockedExchangeAdd64_rel\__int64 \* \__int64|
|_InterlockedExchangeAdd8|char _InterlockedExchangeAdd8 (char vol√°til, \*char)|
|_InterlockedExchangeAdd8_acq|char _InterlockedExchangeAdd8_acq (char vol√°til, \*char)|
|_InterlockedExchangeAdd8_nf|char _InterlockedExchangeAdd8_nf (char vol√°til, \*char)|
|_InterlockedExchangeAdd8_rel|char _InterlockedExchangeAdd8_rel (char vol√°til \*, char)|
|_InterlockedExchangeAdd_acq|longo _InterlockedExchangeAdd_acq (longo vol√°til, \*longo)|
|_InterlockedExchangeAdd_nf|_InterlockedExchangeAdd_nf longo (longo vol√°til, \*longo)|
|_InterlockedExchangeAdd_rel|longo _InterlockedExchangeAdd_rel (longo vol√°til, \*longo)|
|_InterlockedExchangePointer|vazio \* _InterlockedExchangePointer \* (vazio \* vol√°til \*_Target, vazio )|
|_InterlockedExchangePointer_acq|vazio \* _InterlockedExchangePointer_acq \* (vazio \* vol√°til \*_Target, vazio )|
|_InterlockedExchangePointer_nf|vazio \* _InterlockedExchangePointer_nf \* (vazio \* vol√°til \*_Target, vazio )|
|_InterlockedExchange_acq|longo _InterlockedExchange_acq (longo _Target vol√°til, \* longo)|
|_InterlockedExchange_nf|longo _InterlockedExchange_nf (longo _Target vol√°teis, \* longo)|
|_InterlockedIncrement|longo __cdecl _InterlockedIncrement \*(longo vol√°til)|
|_InterlockedIncrement16|_InterlockedIncrement16 curto (curto vol√°til) \*|
|_InterlockedIncrement16_acq|_InterlockedIncrement16_acq curto (curto vol√°til) \*|
|_InterlockedIncrement16_nf|_InterlockedIncrement16_nf curto (curto vol√°til) \*|
|_InterlockedIncrement16_rel|_InterlockedIncrement16_rel curto (curto vol√°til) \*|
|_InterlockedIncrement64|_InterlockedIncrement64\__int64 \*__int64|
|_InterlockedIncrement64_acq|\__int64 \*__int64 _InterlockedIncrement64_acq|
|_InterlockedIncrement64_nf|_InterlockedIncrement64_nf\___int64(_int64 \*vol√°til)|
|_InterlockedIncrement64_rel|_InterlockedIncrement64_rel __int64(\_ \*_int64 vol√°til )|
|_InterlockedIncrement_acq|longo _InterlockedIncrement_acq (longo vol√°til) \*|
|_InterlockedIncrement_nf|longo _InterlockedIncrement_nf (longo vol√°til) \*|
|_InterlockedIncrement_rel|_InterlockedIncrement_rel longo (longo vol√°til) \*|
|_InterlockedOr|_InterlockedOr longo (longo vol√°til, \*longo)|
|_InterlockedOr16|_InterlockedOr16 curto (curto vol√°til, \*curto)|
|_InterlockedOr16_acq|_InterlockedOr16_acq curto (curto vol√°til, \*curto)|
|_InterlockedOr16_nf|_InterlockedOr16_nf curto (curto vol√°til, \*curto)|
|_InterlockedOr16_rel|_InterlockedOr16_rel curto (curto vol√°til, \*curto)|
|_InterlockedOr64|__int64 _InterlockedOr64(\_ \*_int64 \_vol√°til , _int64)|
|_InterlockedOr64_acq|_InterlockedOr64_acq __int64\__int64 \* \__int64|
|_InterlockedOr64_nf|__int64\__InterlockedOr64_nf( \*_int64 \_vol√°til , _int64)|
|_InterlockedOr64_rel|_InterlockedOr64_rel\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedOr8|char _InterlockedOr8 (char vol√°til, \*char)|
|_InterlockedOr8_acq|char _InterlockedOr8_acq (char vol√°til, \*char)|
|_InterlockedOr8_nf|char _InterlockedOr8_nf (char vol√°til, \*char)|
|_InterlockedOr8_rel|char _InterlockedOr8_rel (char vol√°til, \*char)|
|_InterlockedOr_acq|longo _InterlockedOr_acq (longo vol√°til, \*longo)|
|_InterlockedOr_nf|_InterlockedOr_nf longo (longo vol√°til, \*longo)|
|_InterlockedOr_rel|longo _InterlockedOr_rel (longo vol√°til, \*longo)|
|_InterlockedXor|_InterlockedXor longo (longo vol√°til, \*longo)|
|_InterlockedXor16|_InterlockedXor16 curto (curto vol√°til, \*curto)|
|_InterlockedXor16_acq|_InterlockedXor16_acq curto (curto vol√°til, \*curto)|
|_InterlockedXor16_nf|_InterlockedXor16_nf curto (curto vol√°til, \*curto)|
|_InterlockedXor16_rel|_InterlockedXor16_rel curto (curto vol√°til, \*curto)|
|_InterlockedXor64|__int64 _InterlockedXor64(\_ \*_int64 \_vol√°til , _int64)|
|_InterlockedXor64_acq|_InterlockedXor64_acq __int64\__int64 \* \__int64 _int64|
|_InterlockedXor64_nf|__int64 _InterlockedXor64_nf(\_ \*_int64 \_vol√°til , _int64)|
|_InterlockedXor64_rel|_InterlockedXor64_rel\___int64(_int64 \* \_vol√°til , _int64)|
|_InterlockedXor8|char _InterlockedXor8 (char vol√°til, \*char)|
|_InterlockedXor8_acq|char _InterlockedXor8_acq (char vol√°til, \*char)|
|_InterlockedXor8_nf|char _InterlockedXor8_nf (char vol√°til, \*char)|
|_InterlockedXor8_rel|char _InterlockedXor8_rel (char vol√°til, \*char)|
|_InterlockedXor_acq|_InterlockedXor_acq longo (longo vol√°til, \*longo)|
|_InterlockedXor_nf|longo _InterlockedXor_nf (longo vol√°til, \*longo)|
|_InterlockedXor_rel|longo _InterlockedXor_rel (longo vol√°til, \*longo)|

[[Voltar ao topo](#top)]

### <a name="_interlockedbittest-intrinsics"></a>intr√≠nsecos _interlockedbittest

Os intr√≠nsecos de teste de bits interbloqueados simples s√£o comuns a todas as plataformas. A `_acq`ARM `_rel`adiciona `_nf` , e variantes, que apenas modificam a sem√¢ntica de barreira de uma opera√ß√£o, como descrito em [_nf (sem cerca) Sufixo](#nf_suffix) no in√≠cio deste artigo.

|Nome da fun√ß√£o|Prot√≥tipo da fun√ß√£o|
|-------------------|------------------------|
|_interlockedbittestandreset|char n√£o assinado _interlockedbittestandreset \*(longo vol√°til, longo)|
|_interlockedbittestandreset_acq|char n√£o assinado _interlockedbittestandreset_acq \*(longo vol√°til, longo)|
|_interlockedbittestandreset_nf|char n√£o assinado _interlockedbittestandreset_nf \*(longo vol√°til, longo)|
|_interlockedbittestandreset_rel|char n√£o assinado _interlockedbittestandreset_rel \*(longo vol√°til, longo)|
|_interlockedbittestandset|char n√£o assinado _interlockedbittestandset \*(longo vol√°til, longo)|
|_interlockedbittestandset_acq|char n√£o assinado _interlockedbittestandset_acq \*(longo vol√°til, longo)|
|_interlockedbittestandset_nf|char n√£o assinado _interlockedbittestandset_nf \*(longo vol√°til, longo)|
|_interlockedbittestandset_rel|char n√£o assinado _interlockedbittestandset_rel \*(longo vol√°til, longo)|

[[Voltar ao topo](#top)]

## <a name="see-also"></a>Confira tamb√©m

[Intr√≠nseca do compilador](../intrinsics/compiler-intrinsics.md)\
[Intr√≠nsecos ARM64](arm64-intrinsics.md)\
[Refer√™ncia do montador ARM](../assembler/arm/arm-assembler-reference.md)\
[Refer√™ncia em linguagem C++](../cpp/cpp-language-reference.md)
